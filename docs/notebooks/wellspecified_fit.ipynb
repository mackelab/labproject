{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as  mpatches\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from labproject.metrics.wasserstein_sinkhorn import sinkhorn_loss,sinkhorn_algorithm\n",
    "from labproject.metrics.wasserstein_kuhn import kuhn_transport\n",
    "from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance\n",
    "from labproject.metrics.MMD_torch import compute_rbf_mmd,median_heuristic\n",
    "from labproject.data import get_distribution\n",
    "from labproject.utils import set_seed\n",
    "from dataclasses import dataclass\n",
    "from torch.distributions import MultivariateNormal, Categorical\n",
    "set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MO2G:\n",
    "    def __init__(self):\n",
    "        self.means = torch.tensor(\n",
    "            [\n",
    "                [-3.0,1],\n",
    "                [3, -1],\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.covariances = torch.tensor(\n",
    "            [\n",
    "                [[1.0, 0], [0, 1.0]],\n",
    "                [[1.0, 0], [0, 1.0]]\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.weights = torch.tensor([0.2,0.8])\n",
    "\n",
    "        # Create a list of 2D Gaussian distributions\n",
    "        self.gaussians = [\n",
    "            MultivariateNormal(mean, covariance)\n",
    "            for mean, covariance in zip(self.means, self.covariances)\n",
    "        ]\n",
    "\n",
    "    def sample(self, sample_shape):\n",
    "        if isinstance(sample_shape, int):\n",
    "            sample_shape = (sample_shape,)\n",
    "        # Sample from the mixture\n",
    "        categorical = Categorical(self.weights)\n",
    "        sample_indices = categorical.sample(sample_shape)\n",
    "        return torch.stack([self.gaussians[i].sample() for i in sample_indices])\n",
    "\n",
    "    def log_prob(self, input):\n",
    "        probs = torch.stack([g.log_prob(input).exp() for g in self.gaussians])\n",
    "        probs = probs.T * self.weights\n",
    "        return torch.sum(probs, dim=1).log()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base distribution\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "toy_data = get_distribution(\"toy_2d\")\n",
    "MOG = toy_data()\n",
    "MOG = MO2G()\n",
    "num_samples = 1000\n",
    "mixture_samples =MOG.sample(num_samples)\n",
    "mixture_samples = torch.tensor(mixture_samples, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../../matplotlibrc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Gauss(nn.Module):\n",
    "    \"\"\"The model to optimise\"\"\"\n",
    "    def __init__(self,dim):\n",
    "        super(Gauss, self).__init__()\n",
    "        self.mean1 = nn.Parameter(torch.zeros(dim))\n",
    "        self.mean2 = nn.Parameter(torch.zeros(dim))\n",
    "        self.cov1 = nn.Parameter(torch.eye(dim))\n",
    "        self.cov2= nn.Parameter(torch.eye(dim))\n",
    "\n",
    "        init_diag = torch.eye(dim)\n",
    "        self.dim = dim\n",
    "        self.weights = torch.tensor([0.2,0.8])\n",
    "        self.categorical = Categorical(self.weights)\n",
    "        self.G1 = torch.distributions.MultivariateNormal(self.mean1, scale_tril=self.cov1)\n",
    "        self.G2 = torch.distributions.MultivariateNormal(self.mean2, scale_tril=self.cov2)\n",
    "\n",
    "    def sample(self,size):\n",
    "        samples = torch.zeros(size,self.dim)\n",
    "        inds= self.categorical.sample((size,))\n",
    "        s1=self.G1.rsample((sum(inds==0),))\n",
    "        s2=self.G2.rsample((sum(inds==1),))\n",
    "        samples[inds==0]=s1\n",
    "        samples[inds==1]=s2\n",
    "        return samples\n",
    "    \n",
    "    def cov(self):\n",
    "        return [self.G1.covariance_matrix.detach(),self.G2.covariance_matrix.detach()]\n",
    "\n",
    "    def log_prob(self, input):\n",
    "        probs = torch.stack([self.G1.log_prob(input).exp(),self.G2.log_prob(input).exp()])\n",
    "        probs = probs.T * self.weights\n",
    "        return torch.sum(probs, dim=1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mixture_samples[:, 0], mixture_samples[:, 1], label=\"Mixture of Gaussians\")\n",
    "covar = torch.cov(mixture_samples.T)\n",
    "#plt.gca().set_box_aspect(1)\n",
    "\n",
    "\n",
    "#make axis square\n",
    "\n",
    "#plt.xlim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c2st_target(samples1, samples2, density1, density2):\n",
    "    r\"\"\"Computes optimal C2ST and resulting classification cross-entropy loss\n",
    "    for optimization\n",
    "    \"\"\"\n",
    "    density_ratios1 = torch.stack([density1.log_prob(samples1), density2.log_prob(samples1)], dim=-1)\n",
    "    density_ratios2 = torch.stack([density1.log_prob(samples2), density2.log_prob(samples2)], dim=-1)\n",
    "    probs = torch.cat([density_ratios1, density_ratios2], dim=0)\n",
    "    labels = torch.cat([torch.zeros(len(samples1)), torch.ones(len(samples2))], dim=0).long()\n",
    "    loss = -nn.functional.cross_entropy(probs, labels)\n",
    "    with torch.no_grad():\n",
    "        c2st = (sum(density_ratios1[:, 0] >= density_ratios1[:, 1]) + sum(density_ratios2[:, 0] < density_ratios2[:, 1])) / (len(samples1) + len(samples2))\n",
    "    return loss, c2st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_model_C2ST = Gauss(2)\n",
    "\n",
    "model_toy_opt = torch.optim.Adam(gauss_model_C2ST.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters =2500\n",
    "num_samples = 10000\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    model_toy_opt.zero_grad()\n",
    "\n",
    "    model_samples = gauss_model_C2ST.sample(num_samples)\n",
    "    toy_samples = MOG.sample(num_samples)\n",
    "\n",
    "    cent_loss, true_c2st = c2st_target(model_samples, toy_samples, gauss_model_C2ST, MOG)\n",
    "    # c2st_loss = torch.mean(torch.square(preds - 0.5))\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Iter: {}     loss: {}     c2st: {}\".format(epoch, cent_loss.item(), true_c2st.item()))\n",
    "    cent_loss.backward()\n",
    "    model_toy_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD\n",
    "gauss_model_MMD = Gauss(dim=2)\n",
    "with torch.no_grad():\n",
    "    samples = gauss_model_MMD.sample(num_samples)\n",
    "    uniform_samples = MOG.sample(num_samples)\n",
    "    bandwidth = median_heuristic(mixture_samples, uniform_samples)\n",
    "    print(\"bandwidth: \", bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bandwidth = 1\n",
    "optimizer = torch.optim.Adam(gauss_model_MMD.parameters(), lr=0.01)\n",
    "gauss_model_MMD.train()\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    gauss_model_MMD.zero_grad()\n",
    "    samples = gauss_model_MMD.sample(num_samples)\n",
    "    uniform_samples = MOG.sample(num_samples)    #print(samples)\n",
    "    loss = compute_rbf_mmd(samples, uniform_samples, bandwidth=bandwidth)\n",
    "    print(\"Iter: {}     loss: {}\".format(epoch, loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "gauss_model_MMD.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS\n",
    "\n",
    "gauss_model_WS = Gauss(dim=2)\n",
    "optimizer = torch.optim.Adam(gauss_model_WS.parameters(), lr=0.01)\n",
    "gauss_model_WS.train()\n",
    "for epoch in range(n_iters):\n",
    "    gauss_model_WS.zero_grad()\n",
    "    samples = gauss_model_WS.sample(num_samples)\n",
    "    uniform_samples = MOG.sample(num_samples)    #print(samples)\n",
    "    loss = sliced_wasserstein_distance(samples, uniform_samples)#, bandwidth=bandwidth)\n",
    "    print(\"Iter: {}     loss: {}\".format(epoch, loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "gauss_model_WS.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM: https://github.com/joferkington/oost_paper_code/blob/master/error_ellipse.py\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_cov_ellipse(cov, pos, nstd=[1,2], ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an `nstd` sigma error ellipse based on the specified covariance\n",
    "    matrix (`cov`). Additional keyword arguments are passed on to the \n",
    "    ellipse patch artist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        cov : The 2x2 covariance matrix to base the ellipse on\n",
    "        pos : The location of the center of the ellipse. Expects a 2-element\n",
    "            sequence of [x0, y0].\n",
    "        nstd : The radius of the ellipse in numbers of standard deviations.\n",
    "            Defaults to 2 standard deviations.\n",
    "        ax : The axis that the ellipse will be plotted on. Defaults to the \n",
    "            current axis.\n",
    "        Additional keyword arguments are pass on to the ellipse patch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A matplotlib ellipse artist\n",
    "    \"\"\"\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    for std in nstd:\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "        width, height = 2 * std * np.sqrt(vals)\n",
    "        print(pos,width, height,theta)\n",
    "        ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "        ax.add_artist(ellip)\n",
    "    return ellip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM: https://stackoverflow.com/questions/18926031/how-to-extract-a-subset-of-a-colormap-as-a-new-colormap-in-matplotlib\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "cmap = plt.get_cmap('gist_yarg')\n",
    "new_cmap = truncate_colormap(cmap, 0, 0.75)\n",
    "ax[0].imshow(arr, interpolation='nearest', cmap=cmap)\n",
    "ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "#SWD_samples = gauss_model_WS.sample(num_samples).detach().numpy()\n",
    "#MMD_samples = gauss_model_MMD.sample(num_samples).detach().numpy()\n",
    "#C2ST_samples = gauss_model_C2ST.sample(num_samples).detach().numpy()\n",
    "\n",
    "# Create a dataframe for the mixture samples\n",
    "unif_df = pd.DataFrame({'x': uniform_samples[:, 0], 'y': uniform_samples[:, 1]})\n",
    "\n",
    "# Create a dataframe for the SWD mixture samples\n",
    "#SWD_df = pd.DataFrame({'x': SWD_samples[:, 0], 'y': SWD_samples[:, 1]})\n",
    "#MMD_df = pd.DataFrame({'x': MMD_samples[:, 0], 'y': MMD_samples[:, 1]})\n",
    "#C2ST_df = pd.DataFrame({'x': C2ST_samples[:, 0], 'y': MMD_samples[:, 1]})\n",
    "\n",
    "# Plot the probability contours\n",
    "fig,axs = plt.subplots(1,4, figsize = (6.5,3))\n",
    "sns.kdeplot(ax=axs[0],data=unif_df, x='x', y='y',cmap=\"Blues\", fill=True,levels=12)#, thresh=.1,)#, color=\"black\",alpha=0.75, levels=5)\n",
    "\n",
    "alpha_bg=1\n",
    "sns.kdeplot(ax=axs[1],data=unif_df, x='x', y='y', fill=True,cmap=new_cmap,alpha=alpha_bg, levels=12)\n",
    "sns.kdeplot(ax=axs[2],data=unif_df, x='x', y='y', fill=True,cmap=new_cmap,alpha=alpha_bg, levels=12)\n",
    "sns.kdeplot(ax=axs[3],data=unif_df, x='x', y='y', fill=True,cmap=new_cmap,alpha=alpha_bg, levels=12)\n",
    "\n",
    "#x, y = np.mgrid[-10:10:.1, -10:10:.1]\n",
    "#z =torch.exp(gauss_model_WS.log_prob(data)).detach().numpy()\n",
    "##axs[1].contour(x, y, z,colors ='#cc241d')#), cmap='coolwarm',fill=False)\n",
    "##z =torch.exp(gauss_model_MMD.log_prob(data)).detach().numpy()\n",
    "#axs[2].contour(x, y, z,colors ='#eebd35')#), cmap='coolwarm',fill=False)\n",
    "#z =torch.exp(gauss_model_C2ST.log_prob(data)).detach().numpy()\n",
    "#axs[3].contour(x, y, z,colors =\"#458588\")#), cmap='coolwarm',fill=False)\n",
    "std_plot = [np.sqrt(.25),np.sqrt(.5),np.sqrt(1),np.sqrt(2)]\n",
    "std_plot=[.25,.75,1.5,2.5]\n",
    "plot_cov_ellipse(gauss_model_WS.cov().detach().numpy(),gauss_model_WS.mean.detach().numpy(),\n",
    "                 nstd = std_plot ,ax=axs[1],edgecolor='#cc241d', lw=1.5, facecolor='none')\n",
    "#axs[1].scatter(gauss_model_WS.mean.detach().numpy()[0],gauss_model_WS.mean.detach().numpy()[1],\n",
    "#               color='#cc241d',s=1.5)\n",
    "plot_cov_ellipse(gauss_model_MMD.cov().detach().numpy(),gauss_model_MMD.mean.detach().numpy(),\n",
    "                 nstd = std_plot ,ax=axs[3],edgecolor='#eebd35', lw=1.5, facecolor='none')\n",
    "plot_cov_ellipse(gauss_model_C2ST.cov().detach().numpy(),gauss_model_C2ST.mean.detach().numpy(),\n",
    "                 nstd = std_plot ,ax=axs[2],edgecolor='#458588', lw=1.5, facecolor='none')\n",
    "\n",
    "#sns.kdeplot(ax=axs[1],data=SWD_df, x='x', y='y', fill=False,cmap =\"Reds\",levels=7)#,color=\"#cc241d\",alpha=.5, levels=5)\n",
    "#sns.kdeplot(ax=axs[2],data=MMD_df, x='x', y='y', fill=False,cmap='Wistia',levels=7)#color=\"#eebd35\",alpha=.5, levels=5)\n",
    "#sns.kdeplot(ax=axs[3],data=C2ST_df, x='x', y='y', fill=False,cmap='Blues',levels=7)#color=\"#eebd35\",alpha=.5, levels=5)\n",
    "#color_dict = {\"SW\": \"#cc241d\", \"MMD\": \"#eebd35\", \"C2ST\": \"#458588\", \"FID\": \"#8ec07c\"}\n",
    "#ax.scatter(uniform_samples[:20, 0], uniform_samples[:20, 1], color=\"black\",zorder=10)\n",
    "#ax.scatter(SWD_samples[:20, 0], SWD_samples[:20, 1], color=\"coral\",zorder=10)\n",
    "for ax in axs:\n",
    "    ax.spines[['left', 'bottom']].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlim(-8,5)\n",
    "    ax.set_xlim(-10,10)\n",
    "\n",
    "    ax.set_ylim(-7,4)\n",
    "    #make square subplots \n",
    "    ax.set_box_aspect(1)\n",
    "axs[0].set_title(r\"$p_{true}$\")\n",
    "axs[1].set_title(\"SW\",color ='#cc241d')\n",
    "axs[3].set_title(r\"$MMD_1$\",color ='#eebd35')\n",
    "axs[2].set_title(\"C2ST\",color =\"#458588\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"mode.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWD_samples = gauss_model_WS.sample(num_samples).detach().numpy()\n",
    "MMD_samples = gauss_model_MMD.sample(num_samples).detach().numpy()\n",
    "C2ST_samples = gauss_model_C2ST.sample(num_samples).detach().numpy()\n",
    "\n",
    "# Create a dataframe for the mixture samples\n",
    "unif_df = pd.DataFrame({'x': uniform_samples[:, 0], 'y': uniform_samples[:, 1]})\n",
    "\n",
    "# Create a dataframe for the SWD mixture samples\n",
    "SWD_df = pd.DataFrame({'x': SWD_samples[:, 0], 'y': SWD_samples[:, 1]})\n",
    "MMD_df = pd.DataFrame({'x': MMD_samples[:, 0], 'y': MMD_samples[:, 1]})\n",
    "C2ST_df = pd.DataFrame({'x': MMD_samples[:, 0], 'y': MMD_samples[:, 1]})\n",
    "\n",
    "# Plot the probability contours\n",
    "fig,axs = plt.subplots(1,3, figsize = (6,2))\n",
    "sns.kdeplot(ax=axs[0],data=unif_df, x='x', y='y', fill=False, color=\"black\",alpha=0.75, levels=5)\n",
    "sns.kdeplot(ax=axs[1],data=unif_df, x='x', y='y', fill=False, color=\"black\",alpha=0.75, levels=5)\n",
    "sns.kdeplot(ax=axs[2],data=unif_df, x='x', y='y', fill=False, color=\"black\",alpha=0.75, levels=5)\n",
    "\n",
    "sns.kdeplot(ax=axs[0],data=SWD_df, x='x', y='y', fill=False, color=\"tomato\",alpha=0.75, levels=5)\n",
    "sns.kdeplot(ax=axs[1],data=MMD_df, x='x', y='y', fill=False, color=\"yellow\",alpha=0.75, levels=5)\n",
    "sns.kdeplot(ax=axs[2],data=C2ST_df, x='x', y='y', fill=False, color=\"yellow\",alpha=0.75, levels=5)\n",
    "\n",
    "#ax.set_xlim(-1.5, 1.5)\n",
    "#ax.set_ylim(-1.5, 1.5)\n",
    "#ax.scatter(uniform_samples[:20, 0], uniform_samples[:20, 1], color=\"black\",zorder=10)\n",
    "#ax.scatter(SWD_samples[:20, 0], SWD_samples[:20, 1], color=\"coral\",zorder=10)\n",
    "for ax in axs:\n",
    "    ax.spines[['left', 'bottom']].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "axs[0].set_title(\"SWD\")\n",
    "axs[1].set_title(\"MMD\")\n",
    "axs[2].set_title(\"C2ST\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_model_WS.mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_model_WS.mean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
