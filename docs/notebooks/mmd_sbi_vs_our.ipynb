{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "import omegaconf\n",
    "\n",
    "from matplotlib import rc_file\n",
    "rc_file(\"../../matplotlibrc\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "__file__ = os.path.abspath('')\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from labproject.metrics.MMD import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_hat = [.6,.4]\n",
    "sds_hat = [1,2]\n",
    "us_hat = [4,-6]\n",
    "\n",
    "p1 = torch.distributions.Normal(us_hat[0], sds_hat[0]).sample((5000,))\n",
    "\n",
    "u_hat = 0\n",
    "sd_hat = np.sqrt(ws_hat[0]*sds_hat[0]**2 + ws_hat[1]*sds_hat[1]**2 +ws_hat[0]*us_hat[0]**2+ws_hat[1]*us_hat[1]**2-(ws_hat[0]*us_hat[0]+ws_hat[1]*us_hat[1])**2)\n",
    "\n",
    "sd_1=sd_hat\n",
    "u1 = 0\n",
    "\n",
    "# Define the number of Gaussian components in the mixture\n",
    "N = len(ws_hat)\n",
    "\n",
    "# Define Bernoulli distributions for choosing between components\n",
    "bernoulli_dists = [torch.distributions.Bernoulli(torch.tensor(weight)) for weight in ws_hat]\n",
    "\n",
    "# Initialize an empty list to store samples from each component\n",
    "gaussian_samples = []\n",
    "\n",
    "# Sample a total of 1000 samples from the Gaussian mixture model\n",
    "total_samples = 5000\n",
    "samples_count = 0\n",
    "\n",
    "while samples_count < total_samples:\n",
    "    # Sample from each Bernoulli distribution to decide which component to sample from\n",
    "    bernoulli_samples = [bernoulli_dist.sample() for bernoulli_dist in bernoulli_dists]\n",
    "\n",
    "    # Sample from each Gaussian component based on the outcomes of the Bernoulli samples\n",
    "    for i in range(N):\n",
    "        if samples_count < total_samples:\n",
    "            if bernoulli_samples[i].item() == 0:  # Sample from the ith Gaussian component\n",
    "                gaussian_sample = torch.distributions.Normal(us_hat[i], sds_hat[i]).sample()\n",
    "                gaussian_samples.append(gaussian_sample)\n",
    "                samples_count += 1\n",
    "\n",
    "# Convert the list of samples to a PyTorch tensor\n",
    "gaussian_samples_tensor = torch.stack(gaussian_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, name: str, func: callable, **kwargs):\n",
    "        self.name = name\n",
    "        self.func = func\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, x: Tensor, y: Tensor) -> Tensor:\n",
    "        return self.func(x, y, **self.kwargs)\n",
    "\n",
    "class DistComp:\n",
    "    def __init__(self, dataset1: Tensor, dataset2: Tensor, metric: Metric, \n",
    "                 n_perms: int = 1, perm_size=5000, descr=\"\"):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "        self.metric = metric\n",
    "        self.n_perms = n_perms\n",
    "        self.perm_size = perm_size\n",
    "        self.descr = descr\n",
    "\n",
    "        columns = [metric.name]\n",
    "        self.results_df = pd.DataFrame(np.nan, index=range(self.n_perms), columns=columns)\n",
    "\n",
    "    def run_experiment(self):\n",
    "        for i in range(self.n_perms):\n",
    "            dataset2_perm = self.dataset2[torch.randperm(len(self.dataset2))[:self.perm_size]]\n",
    "            dataset1_perm = self.dataset1[torch.randperm(len(self.dataset1))[:self.perm_size]]\n",
    "            self.results_df.loc[i, self.metric.name] = self.metric(dataset1_perm, dataset2_perm).item()\n",
    "    \n",
    "    def reformat_df(self, data):\n",
    "        \"\"\"\n",
    "        reformat the results_df to work with seaborn plot expectations.\n",
    "        \"\"\"\n",
    "        metric = [column_name for _, row in data.iterrows() for column_name, _ in row.items()]\n",
    "        split_ind = [i for i, _ in data.iterrows() for _ in range(len(data.columns))]\n",
    "        distance = [value for _, row in data.iterrows() for _, value in row.items()]\n",
    "\n",
    "        return pd.DataFrame({\"metric\": metric, \"distance\": distance, \"split_ind\": split_ind})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "gammas = np.linspace(0.5, 10, 11)\n",
    "for gamma in gammas:\n",
    "    metrics.append(Metric(f'{gamma}', mmd_rbf, gamma=gamma))\n",
    "\n",
    "datasets = [\n",
    "    (gaussian_samples_tensor, gaussian_samples_tensor ),\n",
    "    (gaussian_samples_tensor, p1),\n",
    "]\n",
    "\n",
    "descr_list = [r'$p_{true} - p_{true}$', r'$p_{true} - p_{1}$']\n",
    "\n",
    "experiments = []\n",
    "\n",
    "for metric in metrics:\n",
    "    for dataset, descr in zip(datasets, descr_list):\n",
    "        experiments.append(\n",
    "            DistComp(dataset[0].unsqueeze(1), dataset[1].unsqueeze(1), metric, n_perms=1, perm_size=1000, descr=descr)\n",
    "        )\n",
    "\n",
    "\n",
    "for experiment in experiments:\n",
    "    experiment.run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/zqh6htjn4310mvxm1plmzny00000gn/T/ipykernel_91607/2739459404.py:34: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([f'{tick:.2f}' for tick in gammas])\n",
      "/var/folders/sk/zqh6htjn4310mvxm1plmzny00000gn/T/ipykernel_91607/2739459404.py:36: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([f'{tick:.5f}' for tick in ax.get_yticks()])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.3471e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 393.701x196.85 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def cm2inch(cm, INCH=2.54):\n",
    "    if isinstance(cm, tuple):\n",
    "        return tuple(i / INCH for i in cm)\n",
    "    else:\n",
    "        return cm / INCH\n",
    "\n",
    "# Combine data from all experiments into a single dataframe\n",
    "all_data = pd.concat([experiment.reformat_df(experiment.results_df).assign(experiment=experiment.descr) for experiment in experiments])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=cm2inch((10, 5)))\n",
    "\n",
    "def generate_palette(hex_color, n_colors=5, saturation=\"light\"):\n",
    "    if saturation == \"light\":\n",
    "        palette = sns.light_palette(hex_color, n_colors=n_colors, as_cmap=False)\n",
    "    elif saturation == \"dark\":\n",
    "        palette = sns.dark_palette(hex_color, n_colors=n_colors, as_cmap=False)\n",
    "    return palette\n",
    "\n",
    "col_dark = generate_palette(\"#eebd35\", saturation='dark')[2]\n",
    "col_light = generate_palette(\"#eebd35\", saturation='light')[-1]\n",
    "\n",
    "colors = [col_light, col_dark]\n",
    "\n",
    "# Assign linestyles based on the experiment\n",
    "linestyles = ['-', '--']  # solid line, dashed line\n",
    "\n",
    "sns.pointplot(data=all_data, x=\"metric\", y=\"distance\", hue=\"experiment\", ax=ax, palette=colors, linestyles=linestyles, linewidth=1.5)\n",
    "\n",
    "# Format x-tick labels to show only the first two digits after the decimal point\n",
    "ax.set_xticklabels([f'{tick:.2f}' for tick in gammas])\n",
    "#do the same for the y axis\n",
    "ax.set_yticklabels([f'{tick:.5f}' for tick in ax.get_yticks()])\n",
    "ax.legend(loc='lower right')\n",
    "ax.title.set_text('MMD for 10d Gaussian vs one dimension shifted')\n",
    "ax.set_ylabel('mmd')\n",
    "ax.set_xlabel('gamma')  \n",
    "#plt.savefig(\"gamma.pdf\",bbox_inches='tight',transparent=True)\n",
    "-1.3471e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "_name_map = {\"X\": 0, \"Y\": 1, \"Z\": 2}\n",
    "\n",
    "class Matrix:\n",
    "    def __init__(self, M, const_diagonal=False):\n",
    "        self.mat = M = torch.as_tensor(M)\n",
    "        self.m, self.n = self.shape = M.shape\n",
    "        self._cache = {}\n",
    "\n",
    "    @_cache\n",
    "    def row_sums(self):\n",
    "        return self.mat.sum(0)\n",
    "\n",
    "    @_cache\n",
    "    def col_sums(self):\n",
    "        return self.mat.sum(1)\n",
    "\n",
    "    @_cache\n",
    "    def row_sums_sq_sum(self):\n",
    "        sums = self.row_sums()\n",
    "        return sums @ sums\n",
    "\n",
    "    @_cache\n",
    "    def col_sums_sq_sum(self):\n",
    "        sums = self.col_sums()\n",
    "        return sums @ sums\n",
    "\n",
    "    @_cache\n",
    "    def sum(self):\n",
    "        if \"row_sums\" in self._cache:\n",
    "            return self.row_sums().sum()\n",
    "        elif \"col_sums\" in self._cache:\n",
    "            return self.col_sums().sum()\n",
    "        else:\n",
    "            return self.mat.sum()\n",
    "\n",
    "    def mean(self):\n",
    "        return self.sum() / (self.m * self.n)\n",
    "\n",
    "    @_cache\n",
    "    def sq_sum(self):\n",
    "        flat = self.mat.view(-1)\n",
    "        return flat @ flat\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{type(self).__name__}, {self.m} by {self.n}>\"\n",
    "\n",
    "\n",
    "class SquareMatrix(Matrix):\n",
    "    def __init__(self, M):\n",
    "        super().__init__(M)\n",
    "        assert self.m == self.n\n",
    "\n",
    "    @_cache\n",
    "    def diagonal(self):\n",
    "        return self.mat.diagonal()\n",
    "\n",
    "    @_cache\n",
    "    def trace(self):\n",
    "        return self.mat.trace()\n",
    "\n",
    "    @_cache\n",
    "    def sq_trace(self):\n",
    "        diag = self.diagonal()\n",
    "        return diag @ diag\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_row_sums(self):\n",
    "        return self.row_sums() - self.diagonal()\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_col_sums(self):\n",
    "        return self.col_sums() - self.diagonal()\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_row_sums_sq_sum(self):\n",
    "        sums = self.offdiag_row_sums()\n",
    "        return sums @ sums\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_col_sums_sq_sum(self):\n",
    "        sums = self.offdiag_col_sums()\n",
    "        return sums @ sums\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_sum(self):\n",
    "        return self.offdiag_row_sums().sum()\n",
    "\n",
    "    def offdiag_mean(self):\n",
    "        return self.offdiag_sum() / (self.n * (self.n - 1))\n",
    "\n",
    "    @_cache\n",
    "    def offdiag_sq_sum(self):\n",
    "        return self.sq_sum() - self.sq_trace()\n",
    "\n",
    "\n",
    "class SymmetricMatrix(SquareMatrix):\n",
    "    def col_sums(self):\n",
    "        return self.row_sums()\n",
    "\n",
    "    def sums(self):\n",
    "        return self.row_sums()\n",
    "\n",
    "    def offdiag_col_sums(self):\n",
    "        return self.offdiag_row_sums()\n",
    "\n",
    "    def offdiag_sums(self):\n",
    "        return self.offdiag_row_sums()\n",
    "\n",
    "    def col_sums_sq_sum(self):\n",
    "        return self.row_sums_sq_sum()\n",
    "\n",
    "    def sums_sq_sum(self):\n",
    "        return self.row_sums_sq_sum()\n",
    "\n",
    "    def offdiag_col_sums_sq_sum(self):\n",
    "        return self.offdiag_row_sums_sq_sum()\n",
    "\n",
    "    def offdiag_sums_sq_sum(self):\n",
    "        return self.offdiag_row_sums_sq_sum()\n",
    "\n",
    "\n",
    "class ConstDiagMatrix(SquareMatrix):\n",
    "    def __init__(self, M, diag_value):\n",
    "        super().__init__(M)\n",
    "        self.diag_value = diag_value\n",
    "\n",
    "    @_cache\n",
    "    def diagonal(self):\n",
    "        return self.mat.new_full((1,), self.diag_value)\n",
    "\n",
    "    def trace(self):\n",
    "        return self.n * self.diag_value\n",
    "\n",
    "    def sq_trace(self):\n",
    "        return self.n * (self.diag_value ** 2)\n",
    "class SymmetricConstDiagMatrix(ConstDiagMatrix, SymmetricMatrix):\n",
    "    pass\n",
    "\n",
    "\n",
    "def as_matrix(M, const_diagonal=False, symmetric=False):\n",
    "    if symmetric:\n",
    "        if const_diagonal is not False:\n",
    "            return SymmetricConstDiagMatrix(M, diag_value=const_diagonal)\n",
    "        else:\n",
    "            return SymmetricMatrix(M)\n",
    "    elif const_diagonal is not False:\n",
    "        return ConstDiagMatrix(M, diag_value=const_diagonal)\n",
    "    elif M.shape[0] == M.shape[1]:\n",
    "        return SquareMatrix(M)\n",
    "    else:\n",
    "        return Matrix(M)\n",
    "\n",
    "def as_tensors(X, *rest):\n",
    "    \"Calls as_tensor on a bunch of args, all of the first's device and dtype.\"\n",
    "    X = torch.as_tensor(X)\n",
    "    return [X] + [\n",
    "        None if r is None else torch.as_tensor(r, device=X.device, dtype=X.dtype)\n",
    "        for r in rest\n",
    "    ]\n",
    "\n",
    "class MMDStatistic:\n",
    "    r\"\"\"The *unbiased* MMD test of :cite:`gretton2012kernel`.\n",
    "    The kernel used is equal to:\n",
    "    .. math ::\n",
    "        k(x, x') = \\sum_{j=1}^k e^{-\\alpha_j\\|x - x'\\|^2},\n",
    "    for the :math:`\\alpha_j` proved in :py:meth:`~.MMDStatistic.__call__`.\n",
    "    Arguments\n",
    "    ---------\n",
    "    n_1: int\n",
    "        The number of points in the first sample.\n",
    "    n_2: int\n",
    "        The number of points in the second sample.\"\"\"\n",
    "\n",
    "    def __init__(self, n_1, n_2):\n",
    "        self.n_1 = n_1\n",
    "        self.n_2 = n_2\n",
    "\n",
    "        # The three constants used in the test.\n",
    "        self.a00 = 1.0 / (n_1 * (n_1 - 1))\n",
    "        self.a11 = 1.0 / (n_2 * (n_2 - 1))\n",
    "        self.a01 = -1.0 / (n_1 * n_2)\n",
    "\n",
    "    def __call__(self, sample_1, sample_2, alphas, ret_matrix=False):\n",
    "        r\"\"\"Evaluate the statistic.\n",
    "        The kernel used is\n",
    "        .. math::\n",
    "            k(x, x') = \\sum_{j=1}^k e^{-\\alpha_j \\|x - x'\\|^2},\n",
    "        for the provided ``alphas``.\n",
    "        Arguments\n",
    "        ---------\n",
    "        sample_1: :class:`torch:torch.autograd.Variable`\n",
    "            The first sample, of size ``(n_1, d)``.\n",
    "        sample_2: variable of shape (n_2, d)\n",
    "            The second sample, of size ``(n_2, d)``.\n",
    "        alphas : list of :class:`float`\n",
    "            The kernel parameters.\n",
    "        ret_matrix: bool\n",
    "            If set, the call with also return a second variable.\n",
    "            This variable can be then used to compute a p-value using\n",
    "            :py:meth:`~.MMDStatistic.pval`.\n",
    "        Returns\n",
    "        -------\n",
    "        :class:`float`\n",
    "            The test statistic.\n",
    "        :class:`torch:torch.autograd.Variable`\n",
    "            Returned only if ``ret_matrix`` was set to true.\"\"\"\n",
    "        sample_12 = torch.cat((sample_1, sample_2), 0)\n",
    "        distances = pdist(sample_12, sample_12, norm=2)\n",
    "\n",
    "        kernels = None\n",
    "        for alpha in alphas:\n",
    "            kernels_a = torch.exp(-alpha * distances ** 2)\n",
    "            if kernels is None:\n",
    "                kernels = kernels_a\n",
    "            else:\n",
    "                kernels = kernels + kernels_a\n",
    "\n",
    "        k_1 = kernels[: self.n_1, : self.n_1]\n",
    "        k_2 = kernels[self.n_1 :, self.n_2 :]\n",
    "        k_12 = kernels[: self.n_1, self.n_2 :]\n",
    "\n",
    "        mmd = (\n",
    "            2 * self.a01 * k_12.sum()\n",
    "            + self.a00 * (k_1.sum() - torch.trace(k_1))\n",
    "            + self.a11 * (k_2.sum() - torch.trace(k_2))\n",
    "        )\n",
    "\n",
    "        if ret_matrix:\n",
    "            return mmd, kernels\n",
    "        else:\n",
    "            return mmd\n",
    "\n",
    "def mmd2_unbiased(K):\n",
    "    return K.XX_m.offdiag_mean() + K.YY_m.offdiag_mean() - 2 * K.XY_m.mean()\n",
    "\n",
    "class LazyKernel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Base class that allows computing kernel matrices among a bunch of datasets,\n",
    "    only computing the matrices when we use them.\n",
    "\n",
    "    Constructor arguments:\n",
    "        - A bunch of matrices we'll compute the kernel among.\n",
    "          2d tensors, with second dimension agreeing, or None;\n",
    "          None is a special value meaning to use the first entry X.\n",
    "          (This is more efficient than passing the same tensor again.)\n",
    "\n",
    "    Access the results with:\n",
    "      - K[0, 1] to get the Tensor between parts 0 and 1.\n",
    "      - K.XX, K.XY, K.ZY, etc: shortcuts, with X=0, Y=1, Z=2.\n",
    "      - K.matrix(0, 1) or K.XY_m: returns a Matrix subclass (see below).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, *rest):\n",
    "        super().__init__()\n",
    "        self._cache = {}\n",
    "        if not hasattr(self, \"const_diagonal\"):\n",
    "            self.const_diagonal = False\n",
    "\n",
    "        # want to use pytorch buffer for parts\n",
    "        # but can't assign a list to those, so munge some names\n",
    "        X, *rest = as_tensors(X, *rest)\n",
    "        if len(X.shape) < 2:\n",
    "            raise ValueError(\n",
    "                \"LazyKernel expects parameters to be at least 2d. \"\n",
    "                \"If your data is 1d, make it [n, 1] with X[:, np.newaxis].\"\n",
    "            )\n",
    "\n",
    "        self.register_buffer(\"_part_0\", X)\n",
    "        self.n_parts = 1\n",
    "        for p in rest:\n",
    "            self.append_part(p)\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._part_0\n",
    "\n",
    "    def _part(self, i):\n",
    "        return self._buffers[f\"_part_{i}\"]\n",
    "\n",
    "    def part(self, i):\n",
    "        p = self._part(i)\n",
    "        return self.X if p is None else p\n",
    "\n",
    "    def n(self, i):\n",
    "        return self.part(i).shape[0]\n",
    "\n",
    "    @property\n",
    "    def ns(self):\n",
    "        return [self.n(i) for i in range(self.n_parts)]\n",
    "\n",
    "    @property\n",
    "    def parts(self):\n",
    "        return [self.part(i) for i in range(self.n_parts)]\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.X.dtype\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.X.device\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{type(self).__name__}({', '.join(str(n) for n in self.ns)})>\"\n",
    "\n",
    "    def _compute(self, A, B):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix between A and B.\n",
    "\n",
    "        Might get called with A = X, B = X, or A = X, B = Y, etc.\n",
    "\n",
    "        Should return a tensor of shape [A.shape[0], B.shape[0]].\n",
    "\n",
    "        This default, slow, version calls self._compute_one(a, b) in a loop.\n",
    "        If you override this, you don't need to implement _compute_one at all.\n",
    "\n",
    "        If you implement _precompute, this gets added to the signature here:\n",
    "            self._compute(A, *self._precompute(A), B, *self._precompute(B)).\n",
    "        The default _precompute returns an empty tuple, so it's _compute(A, B),\n",
    "        but if you make a _precompute that returns [A_squared, A_cubed] then it's\n",
    "            self._compute(A, A_squared, A_cubed, B, B_squared, B_cubed).\n",
    "        \"\"\"\n",
    "        return torch.stack(\n",
    "            [\n",
    "                torch.stack([torch.as_tensor(self._compute_one(a, b)) for b in B])\n",
    "                for a in A\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _compute_one(self, a, b):\n",
    "        raise NotImplementedError(\n",
    "            f\"{type(self).__name__}: need to implement _compute or _compute_one\"\n",
    "        )\n",
    "\n",
    "    def _precompute(self, A):\n",
    "        \"\"\"\n",
    "        Compute something extra for each part A.\n",
    "\n",
    "        Can be used to share computation between kernel(X, X) and kernel(X, Y).\n",
    "\n",
    "        We end up calling basically (but with caching)\n",
    "            self._compute(A, *self._precompute(A), B, *self._precompute(B))\n",
    "        This default _precompute returns an empty tuple, so it's\n",
    "            self._compute(A, B)\n",
    "        But if you return [A_squared], it'd be\n",
    "            self._compute(A, A_squared, B, B_squared)\n",
    "        and so on.\n",
    "        \"\"\"\n",
    "        return ()\n",
    "\n",
    "    @_cache\n",
    "    def _precompute_i(self, i):\n",
    "        p = self._part(i)\n",
    "        if p is None:\n",
    "            return self._precompute_i(0)\n",
    "        return self._precompute(p)\n",
    "\n",
    "    @_cache\n",
    "    def __getitem__(self, k):\n",
    "        try:\n",
    "            i, j = k\n",
    "        except ValueError:\n",
    "            raise KeyError(\"You should index kernels with pairs\")\n",
    "\n",
    "        A = self._part(i)\n",
    "        if A is None:\n",
    "            return self[0, j]\n",
    "\n",
    "        B = self._part(j)\n",
    "        if B is None:\n",
    "            return self[i, 0]\n",
    "\n",
    "        if i > j:\n",
    "            return self[j, i].t()\n",
    "\n",
    "        A_info = self._precompute_i(i)\n",
    "        B_info = self._precompute_i(j)\n",
    "        return self._compute(A, *A_info, B, *B_info)\n",
    "\n",
    "    @_cache\n",
    "    def matrix(self, i, j):\n",
    "        if self._part(i) is None:\n",
    "            return self.matrix(0, j)\n",
    "\n",
    "        if self._part(j) is None:\n",
    "            return self.matrix(i, 0)\n",
    "\n",
    "        k = self[i, j]\n",
    "        if i == j:\n",
    "            return as_matrix(k, const_diagonal=self.const_diagonal, symmetric=True)\n",
    "        else:\n",
    "            return as_matrix(k)\n",
    "\n",
    "    @_cache\n",
    "    def joint(self, *inds):\n",
    "        if not inds:\n",
    "            return self.joint(*range(self.n_parts))\n",
    "        return torch.cat([torch.cat([self[i, j] for j in inds], 1) for i in inds], 0)\n",
    "\n",
    "    @_cache\n",
    "    def joint_m(self, *inds):\n",
    "        if not inds:\n",
    "            return self.joint_m(*range(self.n_parts))\n",
    "        return as_matrix(\n",
    "            self.joint(*inds), const_diagonal=self.const_diagonal, symmetric=True\n",
    "        )\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        # self.X, self.Y, self.Z\n",
    "        if name in _name_map:\n",
    "            i = _name_map[name]\n",
    "            if i < self.n_parts:\n",
    "                return self.part(i)\n",
    "            else:\n",
    "                raise AttributeError(f\"have {self.n_parts} parts, asked for {i}\")\n",
    "\n",
    "        # self.XX, self.XY, self.YZ, etc; also self.XX_m\n",
    "        ret_matrix = False\n",
    "        if len(name) == 4 and name.endswith(\"_m\"):\n",
    "            ret_matrix = True\n",
    "            name = name[:2]\n",
    "\n",
    "        if len(name) == 2:\n",
    "            i = _name_map.get(name[0], np.inf)\n",
    "            j = _name_map.get(name[1], np.inf)\n",
    "            if i < self.n_parts and j < self.n_parts:\n",
    "                return self.matrix(i, j) if ret_matrix else self[i, j]\n",
    "            else:\n",
    "                raise AttributeError(f\"have {self.n_parts} parts, asked for {i}, {j}\")\n",
    "\n",
    "        return super().__getattr__(name)\n",
    "\n",
    "    def _invalidate_cache(self, i):\n",
    "        for k in list(self._cache.keys()):\n",
    "            if (\n",
    "                i in k[1:]\n",
    "                or any(isinstance(arg, tuple) and i in arg for arg in k[1:])\n",
    "                or k in [(\"joint\",), (\"joint_m\",)]\n",
    "            ):\n",
    "                del self._cache[k]\n",
    "\n",
    "    def drop_last_part(self):\n",
    "        assert self.n_parts >= 2\n",
    "        i = self.n_parts - 1\n",
    "        self._invalidate_cache(i)\n",
    "        del self._buffers[f\"_part_{i}\"]\n",
    "        self.n_parts -= 1\n",
    "\n",
    "    def change_part(self, i, new):\n",
    "        assert i < self.n_parts\n",
    "        if new is not None and new.shape[1:] != self.X.shape[1:]:\n",
    "            raise ValueError(f\"X has shape {self.X.shape}, new entry has {new.shape}\")\n",
    "        self._invalidate_cache(i)\n",
    "        self._buffers[f\"_part_{i}\"] = new\n",
    "\n",
    "    def append_part(self, new):\n",
    "        if new is not None and new.shape[1:] != self.X.shape[1:]:\n",
    "            raise ValueError(f\"X has shape {self.X.shape}, new entry has {new.shape}\")\n",
    "        self._buffers[f\"_part_{self.n_parts}\"] = new\n",
    "        self.n_parts += 1\n",
    "\n",
    "    def __copy__(self):\n",
    "        \"\"\"\n",
    "        Doesn't deep-copy the data tensors, but copies dictionaries so that\n",
    "        change_part/etc don't affect the original.\n",
    "        \"\"\"\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        to_copy = {\"_cache\", \"_buffers\", \"_parameters\", \"_modules\"}\n",
    "        result.__dict__.update(\n",
    "            {k: v.copy() if k in to_copy else v for k, v in self.__dict__.items()}\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def _apply(self, fn):  # used in to(), cuda(), etc\n",
    "        super()._apply(fn)\n",
    "        for key, val in self._cache.items():\n",
    "            if val is not None:\n",
    "                self._cache[key] = fn(val)\n",
    "        return self\n",
    "\n",
    "    def as_tensors(self, *args, **kwargs):\n",
    "        \"Helper that makes everything a tensor with self.X's type.\"\n",
    "        kwargs.setdefault(\"device\", self.X.device)\n",
    "        kwargs.setdefault(\"dtype\", self.X.dtype)\n",
    "        return tuple(None if r is None else torch.as_tensor(r, **kwargs) for r in args)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Matrix wrappers that cache sums / etc. Including various subclasses; see\n",
    "# as_matrix() to pick between them appropriately.\n",
    "\n",
    "# TODO: could support a matrix transpose that shares the cache appropriately\n",
    "\n",
    "\n",
    "class ExpQuadKernel(LazyKernel):\n",
    "    def __init__(self, *parts, sigma=1):\n",
    "        super().__init__(*parts)\n",
    "        self.sigma = sigma\n",
    "        self.const_diagonal = 1  # Says that k(x, x) = 1 for any x.\n",
    "        # Just a slight optimization; not really necessary.\n",
    "\n",
    "    # TODO: implement _compute (maybe with _precompute) or _compute_one\n",
    "    def _precompute(self, A):\n",
    "        # Squared norms of each data point\n",
    "        return [torch.einsum(\"ij,ij->i\", A, A)]\n",
    "\n",
    "    def _compute(self, A, A_sqnorms, B, B_sqnorms):\n",
    "        D2 = A_sqnorms[:, None] + B_sqnorms[None, :] - 2 * (A @ B.t())\n",
    "        return torch.exp(D2 / (-2 * self.sigma ** 2))\n",
    "\n",
    "def get_default_device() -> torch.device:\n",
    "    device = torch.ones((1,)).device\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def mmd(\n",
    "    X: torch.Tensor,\n",
    "    Y: torch.Tensor,\n",
    "    implementation: str = \"tp_sutherland\",\n",
    "    z_score: bool = False,\n",
    "    bandwidth: str = \"X\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Estimate MMD^2 statistic with Gaussian kernel\n",
    "\n",
    "    Currently different implementations are available, in order to validate accuracy and compare speeds. The widely used median heuristic for bandwidth-selection of the Gaussian kernel is used.\n",
    "    \"\"\"\n",
    "    if torch.isnan(X).any() or torch.isnan(Y).any():\n",
    "        return torch.tensor(float(\"nan\"))\n",
    "\n",
    "    tic = time.time()  # noqa\n",
    "\n",
    "    if z_score:\n",
    "        X_mean = torch.mean(X, axis=0)\n",
    "        X_std = torch.std(X, axis=0)\n",
    "        X = (X - X_mean) / X_std\n",
    "        Y = (Y - X_mean) / X_std\n",
    "\n",
    "    n_1 = X.shape[0]\n",
    "    n_2 = Y.shape[0]\n",
    "\n",
    "    # Bandwidth\n",
    "    if bandwidth == \"X\":\n",
    "        sigma_tensor = torch.median(torch.pdist(X))\n",
    "    elif bandwidth == \"XY\":\n",
    "        sigma_tensor = torch.median(torch.pdist(torch.cat([X, Y])))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Compute MMD\n",
    "    if implementation == \"tp_sutherland\":\n",
    "        K = ExpQuadKernel(X, Y, sigma=sigma_tensor)\n",
    "        statistic = mmd2_unbiased(K)\n",
    "\n",
    "    elif implementation == \"tp_djolonga\":\n",
    "        alpha = 1 / (2 * sigma_tensor ** 2)\n",
    "        test = MMDStatistic(n_1, n_2)\n",
    "        statistic = test(X, Y, [alpha])\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    toc = time.time()  # noqa\n",
    "    # log.info(f\"Took {toc-tic:.3f}sec\")\n",
    "\n",
    "    return statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmd but squared: [tensor(-0.0002), tensor(0.5334)]\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    (gaussian_samples_tensor, gaussian_samples_tensor ),\n",
    "    (gaussian_samples_tensor, p1),\n",
    "]\n",
    "\n",
    "experiments = []\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    experiments.append(\n",
    "        mmd(dataset[0].unsqueeze(1), dataset[1].unsqueeze(1))\n",
    "    )\n",
    "\n",
    "\n",
    "print('mmd but squared:', experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:  5.053723335266113\n"
     ]
    }
   ],
   "source": [
    "print('gamma: ', torch.median(torch.pdist(gaussian_samples_tensor.unsqueeze(1))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
