{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A Practical Guide to Statistical Distances for Evaluating Generative Models in Science","text":"<p>Generative models are highly useful in many disciplines of science. How do we evaluate them? As the data generated by these models is often high-dimensional and/or non-parametric, we can typically not resort to classical statistical tests. This paper aims to provide an accessible entry point to a understanding popular statistical distances proposed and adopted by the machine learning in science community, requiring only foundational knowledge in mathematics or statistics. We focus on four commonly used classes of statistical distances: obtaining a distance using classifiers (e.g. classifier two-sample tests), using embeddings through kernels (e.g. Maximum Mean Discrepancy) or neural networks (e.g. Frechet Inception Distance), and slicing (e.g. sliced Wasserstein). We highlight their merits, scalability, complexity and pitfalls, which are all illustrated in accompanying notebooks. We then apply each metric to multiple examples generative models in scientific applications, spanning image generation, neuroscience... . We this aim to empower researchers to use, critically assess and interpret statistical distances for generative models in science.</p>"},{"location":"#installation","title":"Installation","text":"<p>Please execute the following commands in your terminal to install the labproject package and its dependencies. We recommend using a conda environment to avoid conflicts with other packages.</p> <pre><code># clone the repository\ngit clone https://github.com/mackelab/labproject.git\n\n# (optional but recommended) create conda environment\nconda create -n labproject python=3.9\nconda activate labproject\n\n# install labproject package with dependencies\npython3 -m pip install --upgrade pip\ncd labproject\npip install -e \".[dev,docs]\"\n\n# install pre-commit hooks for black auto-formatting\npre-commit install\n</code></pre> <p><code>pip install -e .</code> installs the labproject package in editable mode, i.e. changes to the code are immediately reflected in the package.</p> <p>The environment now contains, <code>numpy</code>, <code>scipy</code>, <code>matplotlib</code>, <code>torch</code>, and <code>jupyter</code>.</p>"},{"location":"#development","title":"Development","text":"<p>Develop code in your desired way, e.g. in local notebooks (you don't commit them, they will be automatically ignored). The public notebooks i.e. for the website can be found in <code>docs/notebooks/</code>, if you want to share the whole notebook then move it in this directory.</p>"},{"location":"#metrics","title":"Metrics","text":"<p>If you implemented a well-documented and reliable function that computes a metric, then move it to in <code>labproject/metrics</code> simply by add a new file <code>my_metric.py</code>.</p>"},{"location":"#plotting","title":"Plotting","text":"<p>If you implemented a nice plotting function, then move it to in <code>labproject/plotting.py</code>. Especially if it is applicable to multiple tasks.</p>"},{"location":"#running-experiments","title":"Running experiments","text":"<p>After committing and pushing your changes, GitHub will execute every <code>run_{name}.py</code> and update the figures in Overleaf. </p> <p>You can also run it yourself with <code>python labproject/run_{name}.py</code>. Any results, will however not be pushed into the repository.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>We use mkdocs to create the public version of our tutorials (notebooks) and the API documentation. mkdocs are written in Markdown and are found in <code>docs/</code>.</p> <p>After installing the necessary dependencies with <code>pip install -e \".[docs]\"</code>, you can view your local version with <code>mkdocs serve</code> in <code>labproject/</code> and then open http://127.0.0.1:8000/. Every push to the main branch will also publish the current version on: http://www.mackelab.org/labproject/ </p> <p>To add your notebooks as pages in the docs, add the following to <code>mkdocs.yml</code>: <pre><code>pages:\n  - Notebooks: \n    - Example Notebook: notebooks/example.ipynb\n    - FID notebook: notebooks/fid.ipynb\n    - UR_NOTEBOOK_NAME: notebook/UR_NOTEBOOK_FILE\n</code></pre></p> <p>To add your functions to the API documentation, add the following to <code>docs/api.md</code>: <pre><code>### Your module\n::: labproject.your_module\n    options:\n      heading_level: 4\n</code></pre> To build it locally use <code>mkdocs build</code> (or <code>mkdocs serve</code> to view it locally). After pushing to the main branch, the documentation will be automatically updated.</p> <p>For adding new pages, create a new markdown file in <code>docs/</code> and add it to <code>mkdocs.yml</code>: <pre><code>pages:\n  - 'your_new_page.md'\n</code></pre></p> <p>Every docstring in the code will be automatically added to the API documentation. We will use \"Google Style\" docstrings, see here for an example.</p>"},{"location":"#notebooks","title":"Notebooks","text":"<p>The jupyter notebooks are found in <code>docs/notebooks/</code>.</p> <p>For your convenience, at the beginning of the jupyter notebook, run   <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> for automatic reloading of modules, in case you make any running changes to the labproject code.</p>"},{"location":"api/","title":"API reference for development package labproject","text":"<p>Here all functions will be documented that are part of the public API of the labproject package.</p>"},{"location":"api/#metrics","title":"Metrics","text":"<p>Best practices for developing metrics:</p> <ol> <li>Please do everything in torch, and if that is not possible, cast the output to torch.Tensor.</li> <li>The function should be well-documented, including type hints.</li> <li>The function should be tested with a simple example.</li> <li>Add an assert at the beginning for shape checking (N,D), see examples.</li> </ol>"},{"location":"api/#gaussian-kl-divergence","title":"Gaussian KL divergence","text":""},{"location":"api/#labproject.metrics.gaussian_kl.gaussian_kl_divergence","title":"<code>gaussian_kl_divergence(real_samples, fake_samples)</code>","text":"<p>Compute the KL divergence between Gaussian approximations of real and fake samples. Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).</p> <p>In detail, for each set of samples, we calculate the mean and covariance matrix.</p> \\[ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i \\] \\[ \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T \\] <p>Then we calculate the KL divergence between the two Gaussian approximations:</p> \\[ D_{KL}(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}) || N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) = \\frac{1}{2} \\left( \\text{tr}(\\Sigma_{\\text{fake}}^{-1} \\Sigma_{\\text{real}}) + (\\mu_{\\text{fake}} - \\mu_{\\text{real}})^T \\Sigma_{\\text{fake}}^{-1} (\\mu_{\\text{fake}} - \\mu_{\\text{real}}) - k + \\log \\frac{|\\Sigma_{\\text{fake}}|}{|\\Sigma_{\\text{real}}|} \\right) \\] <p>Parameters:</p> Name Type Description Default <code>real_samples</code> <code>Tensor</code> <p>A tensor representing the real samples.</p> required <code>fake_samples</code> <code>Tensor</code> <p>A tensor representing the fake samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The KL divergence between the two Gaussian approximations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; kl_div = gaussian_kl_divergence(real_samples, fake_samples)\n&gt;&gt;&gt; print(kl_div)\n</code></pre> Source code in <code>labproject/metrics/gaussian_kl.py</code> <pre><code>def gaussian_kl_divergence(real_samples: Tensor, fake_samples: Tensor) -&gt; Tensor:\n    r\"\"\"\n    Compute the KL divergence between Gaussian approximations of real and fake samples.\n    Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).\n\n    In detail, for each set of samples, we calculate the mean and covariance matrix.\n\n    $$ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n\n\n    $$\n    \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad\n    \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T\n    $$\n\n    Then we calculate the KL divergence between the two Gaussian approximations:\n\n    $$\n    D_{KL}(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}) || N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) =\n    \\frac{1}{2} \\left( \\text{tr}(\\Sigma_{\\text{fake}}^{-1} \\Sigma_{\\text{real}}) + (\\mu_{\\text{fake}} - \\mu_{\\text{real}})^T \\Sigma_{\\text{fake}}^{-1} (\\mu_{\\text{fake}} - \\mu_{\\text{real}})\n    - k + \\log \\frac{|\\Sigma_{\\text{fake}}|}{|\\Sigma_{\\text{real}}|} \\right)\n    $$\n\n    Args:\n        real_samples (torch.Tensor): A tensor representing the real samples.\n        fake_samples (torch.Tensor): A tensor representing the fake samples.\n\n    Returns:\n        torch.Tensor: The KL divergence between the two Gaussian approximations.\n\n    Examples:\n        &gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; kl_div = gaussian_kl_divergence(real_samples, fake_samples)\n        &gt;&gt;&gt; print(kl_div)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(real_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(fake_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    # calculate mean and covariance of real and fake samples\n    mu_real = real_samples.mean(dim=0)\n    mu_fake = fake_samples.mean(dim=0)\n    cov_real = torch.cov(real_samples.t())\n    cov_fake = torch.cov(fake_samples.t())\n\n    # ensure the covariance matrices are invertible\n    eps = 1e-8\n    cov_real += torch.eye(cov_real.size(0)) * eps\n    cov_fake += torch.eye(cov_fake.size(0)) * eps\n\n    # compute KL divergence\n    inv_cov_fake = torch.inverse(cov_fake)\n    kl_div = 0.5 * (\n        torch.trace(inv_cov_fake @ cov_real)\n        + (mu_fake - mu_real).dot(inv_cov_fake @ (mu_fake - mu_real))\n        - real_samples.size(1)\n        + torch.log(torch.det(cov_fake) / torch.det(cov_real))\n    )\n\n    return kl_div\n</code></pre>"},{"location":"api/#gaussian-wasserstein","title":"Gaussian Wasserstein","text":""},{"location":"api/#labproject.metrics.gaussian_squared_wasserstein.gaussian_squared_w2_distance","title":"<code>gaussian_squared_w2_distance(real_samples, fake_samples)</code>","text":"<p>Compute the squared Wasserstein distance between Gaussian approximations of real and fake samples. Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).</p> <p>In detail, for each set of samples, we calculate the mean and covariance matrix.</p> \\[ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i \\] \\[ \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T \\] <p>Then we calculate the squared Wasserstein distance between the two Gaussian approximations:</p> \\[ d_{W_2}^2(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}), N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) = \\left\\| \\mu_{\\text{real}} - \\mu_{\\text{fake}} \\right\\|^2 + \\text{tr}(\\Sigma_{\\text{real}} + \\Sigma_{\\text{fake}} - 2 \\sqrt{\\Sigma_{\\text{real}} \\Sigma_{\\text{fake}}}) \\] <p>Parameters:</p> Name Type Description Default <code>real_samples</code> <code>Tensor</code> <p>A tensor representing the real samples.</p> required <code>fake_samples</code> <code>Tensor</code> <p>A tensor representing the fake samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The KL divergence between the two Gaussian approximations.</p> References <p>[1] https://en.wikipedia.org/wiki/Wasserstein_metric [2] https://arxiv.org/pdf/1706.08500.pdf</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; w2 = gaussian_squared_w2_distance(real_samples, fake_samples)\n&gt;&gt;&gt; print(w2)\n</code></pre> Source code in <code>labproject/metrics/gaussian_squared_wasserstein.py</code> <pre><code>def gaussian_squared_w2_distance(real_samples: Tensor, fake_samples: Tensor) -&gt; Tensor:\n    r\"\"\"\n    Compute the squared Wasserstein distance between Gaussian approximations of real and fake samples.\n    Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).\n\n    In detail, for each set of samples, we calculate the mean and covariance matrix.\n\n    $$ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n\n\n    $$\n    \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad\n    \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T\n    $$\n\n    Then we calculate the squared Wasserstein distance between the two Gaussian approximations:\n\n    $$\n    d_{W_2}^2(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}), N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) =\n    \\left\\| \\mu_{\\text{real}} - \\mu_{\\text{fake}} \\right\\|^2 + \\text{tr}(\\Sigma_{\\text{real}} + \\Sigma_{\\text{fake}} - 2 \\sqrt{\\Sigma_{\\text{real}} \\Sigma_{\\text{fake}}})\n    $$\n\n    Args:\n        real_samples (torch.Tensor): A tensor representing the real samples.\n        fake_samples (torch.Tensor): A tensor representing the fake samples.\n\n    Returns:\n        torch.Tensor: The KL divergence between the two Gaussian approximations.\n\n    References:\n        [1] https://en.wikipedia.org/wiki/Wasserstein_metric\n        [2] https://arxiv.org/pdf/1706.08500.pdf\n\n    Examples:\n        &gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; w2 = gaussian_squared_w2_distance(real_samples, fake_samples)\n        &gt;&gt;&gt; print(w2)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(real_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(fake_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    # calculate mean and covariance of real and fake samples\n    mu_real = real_samples.mean(dim=0)\n    mu_fake = fake_samples.mean(dim=0)\n    cov_real = torch.cov(real_samples.t())\n    cov_fake = torch.cov(fake_samples.t())\n\n    # ensure the covariance matrices are invertible\n    eps = 1e-8\n    cov_real += torch.eye(cov_real.size(0)) * eps\n    cov_fake += torch.eye(cov_fake.size(0)) * eps\n\n    # compute KL divergence\n    mean_dist = torch.norm(mu_real - mu_fake, p=2)\n    cov_sqrt = torch.from_numpy(scipy.linalg.sqrtm((cov_real @ cov_fake).numpy().real))\n    cov_dist = torch.trace(cov_real + cov_fake - 2 * cov_sqrt)\n    w2_squared_dist = mean_dist**2 + cov_dist\n\n    return w2_squared_dist\n</code></pre>"},{"location":"api/#sliced-wasserstein","title":"Sliced Wasserstein","text":""},{"location":"api/#labproject.metrics.sliced_wasserstein.rand_projections","title":"<code>rand_projections(embedding_dim, num_samples)</code>","text":"<p>This function generates num_samples random samples from the latent space's unti sphere.r</p> <p>Parameters:</p> Name Type Description Default <code>embedding_dim</code> <code>int</code> <p>dimention of the embedding</p> required <code>sum_samples</code> <code>int</code> <p>number of samples</p> required Return <p>torch.tensor: tensor of size (num_samples, embedding_dim)</p> Source code in <code>labproject/metrics/sliced_wasserstein.py</code> <pre><code>def rand_projections(embedding_dim: int, num_samples: int):\n    \"\"\"\n    This function generates num_samples random samples from the latent space's unti sphere.r\n\n    Args:\n        embedding_dim (int): dimention of the embedding\n        sum_samples (int): number of samples\n\n    Return :\n        torch.tensor: tensor of size (num_samples, embedding_dim)\n    \"\"\"\n\n    ws = torch.randn((num_samples, embedding_dim))\n    projection = ws / torch.norm(ws, dim=-1, keepdim=True)\n    return projection\n</code></pre>"},{"location":"api/#labproject.metrics.sliced_wasserstein.sliced_wasserstein_distance","title":"<code>sliced_wasserstein_distance(encoded_samples, distribution_samples, num_projections=50, p=2, device='cpu')</code>","text":"<p>Sliced Wasserstein distance between encoded samples and distribution samples</p> <p>Parameters:</p> Name Type Description Default <code>encoded_samples</code> <code>Tensor</code> <p>tensor of encoded training samples</p> required <code>distribution_samples</code> <code>Tensor</code> <p>tensor drawn from the prior distribution</p> required <code>num_projection</code> <code>int</code> <p>number of projections to approximate sliced wasserstein distance</p> required <code>p</code> <code>int</code> <p>power of distance metric</p> <code>2</code> <code>device</code> <code>device</code> <p>torch device 'cpu' or 'cuda' gpu</p> <code>'cpu'</code> Return <p>torch.Tensor: Tensor of wasserstein distances of size (num_projections, 1)</p> Source code in <code>labproject/metrics/sliced_wasserstein.py</code> <pre><code>def sliced_wasserstein_distance(\n    encoded_samples: Tensor,\n    distribution_samples: Tensor,\n    num_projections: int = 50,\n    p: int = 2,\n    device: str = \"cpu\",\n):\n    \"\"\"\n    Sliced Wasserstein distance between encoded samples and distribution samples\n\n    Args:\n        encoded_samples (torch.Tensor): tensor of encoded training samples\n        distribution_samples (torch.Tensor): tensor drawn from the prior distribution\n        num_projection (int): number of projections to approximate sliced wasserstein distance\n        p (int): power of distance metric\n        device (torch.device): torch device 'cpu' or 'cuda' gpu\n\n    Return:\n        torch.Tensor: Tensor of wasserstein distances of size (num_projections, 1)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(encoded_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(distribution_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    embedding_dim = distribution_samples.size(-1)\n\n    projections = rand_projections(embedding_dim, num_projections).to(device)\n\n    encoded_projections = encoded_samples.matmul(projections.transpose(-2, -1))\n\n    distribution_projections = distribution_samples.matmul(projections.transpose(-2, -1))\n\n    wasserstein_distance = (\n        torch.sort(encoded_projections.transpose(-2, -1), dim=-1)[0]\n        - torch.sort(distribution_projections.transpose(-2, -1), dim=-1)[0]\n    )\n\n    wasserstein_distance = torch.pow(torch.abs(wasserstein_distance), p)\n\n    return torch.pow(torch.mean(wasserstein_distance, dim=(-2, -1)), 1 / p)\n</code></pre>"},{"location":"api/#main-modules","title":"Main Modules","text":""},{"location":"api/#data","title":"Data","text":""},{"location":"api/#labproject.data.download_file","title":"<code>download_file(remote_path, local_path)</code>","text":"<p>Downloads a file from the Hetzner Storage Box.</p> <p>Parameters:</p> Name Type Description Default <code>remote_path</code> <code>str</code> <p>The path to the remote file to be downloaded.</p> required <code>local_path</code> <code>str</code> <p>The path where the file should be saved locally.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the download is successful, False otherwise.</p> Example <p>if download_file('path/to/remote/file.txt', 'path/to/save/file.txt'):     print(\"Download successful\") else:     print(\"Download failed\")</p> Source code in <code>labproject/data.py</code> <pre><code>def download_file(remote_path, local_path):\n    r\"\"\"\n    Downloads a file from the Hetzner Storage Box.\n\n    Args:\n        remote_path (str): The path to the remote file to be downloaded.\n        local_path (str): The path where the file should be saved locally.\n\n    Returns:\n        bool: True if the download is successful, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if download_file('path/to/remote/file.txt', 'path/to/save/file.txt'):\n        &gt;&gt;&gt;     print(\"Download successful\")\n        &gt;&gt;&gt; else:\n        &gt;&gt;&gt;     print(\"Download failed\")\n    \"\"\"\n    url = f\"{STORAGEBOX_URL}/remote.php/dav/files/{HETZNER_STORAGEBOX_USERNAME}/{remote_path}\"\n    auth = HTTPBasicAuth(HETZNER_STORAGEBOX_USERNAME, HETZNER_STORAGEBOX_PASSWORD)\n    response = requests.get(url, auth=auth)\n    if response.status_code == 200:\n        with open(local_path, \"wb\") as f:\n            f.write(response.content)\n        return True\n    return False\n</code></pre>"},{"location":"api/#labproject.data.get_dataset","title":"<code>get_dataset(name)</code>","text":"<p>Get a dataset by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset</p> required <code>n</code> <code>int</code> <p>Number of samples</p> required <code>d</code> <code>int</code> <p>Dimensionality of the samples</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Dataset</p> Source code in <code>labproject/data.py</code> <pre><code>def get_dataset(name: str) -&gt; torch.Tensor:\n    r\"\"\"Get a dataset by name\n\n    Args:\n        name (str): Name of the dataset\n        n (int): Number of samples\n        d (int): Dimensionality of the samples\n\n    Returns:\n        torch.Tensor: Dataset\n    \"\"\"\n    assert name in DATASETS, f\"Dataset {name} not found, please register it first \"\n    return DATASETS[name]\n</code></pre>"},{"location":"api/#labproject.data.get_distribution","title":"<code>get_distribution(name)</code>","text":"<p>Get a distribution by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the distribution</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Distribution</p> Source code in <code>labproject/data.py</code> <pre><code>def get_distribution(name: str) -&gt; torch.Tensor:\n    r\"\"\"Get a distribution by name\n\n    Args:\n        name (str): Name of the distribution\n\n    Returns:\n        torch.Tensor: Distribution\n    \"\"\"\n    assert name in DISTRIBUTIONS, f\"Distribution {name} not found, please register it first \"\n    return DISTRIBUTIONS[name]\n</code></pre>"},{"location":"api/#labproject.data.load_cifar10","title":"<code>load_cifar10(n, save_path='data', train=True, batch_size=100, shuffle=False, num_workers=1, device='cpu')</code>","text":"<p>Load a subset of cifar10</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of samples to load</p> required <code>save_path</code> <code>str</code> <p>Path to save files. Defaults to \"data\".</p> <code>'data'</code> <code>train</code> <code>bool</code> <p>Train or test. Defaults to True.</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>Batch size. Defaults to 100.</p> <code>100</code> <code>shuffle</code> <code>bool</code> <p>Shuffle. Defaults to False.</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Parallel workers. Defaults to 1.</p> <code>1</code> <code>device</code> <code>str</code> <p>Device. Defaults to \"cpu\".</p> <code>'cpu'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Cifar10 embeddings</p> Source code in <code>labproject/data.py</code> <pre><code>def load_cifar10(\n    n: int, save_path=\"data\", train=True, batch_size=100, shuffle=False, num_workers=1, device=\"cpu\"\n) -&gt; torch.Tensor:\n    \"\"\"Load a subset of cifar10\n\n    Args:\n        n (int): Number of samples to load\n        save_path (str, optional): Path to save files. Defaults to \"data\".\n        train (bool, optional): Train or test. Defaults to True.\n        batch_size (int, optional): Batch size. Defaults to 100.\n        shuffle (bool, optional): Shuffle. Defaults to False.\n        num_workers (int, optional): Parallel workers. Defaults to 1.\n        device (str, optional): Device. Defaults to \"cpu\".\n\n    Returns:\n        torch.Tensor: Cifar10 embeddings\n    \"\"\"\n    transform = transforms.Compose(\n        [\n            transforms.ToTensor(),\n        ]\n    )\n    cifar10 = CIFAR10(root=save_path, train=train, download=True, transform=transform)\n    dataloader = torch.utils.data.DataLoader(\n        cifar10, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n    )\n    dataset_subset = Subset(dataloader.dataset, range(n))\n    dataloader = DataLoader(\n        dataset_subset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n    )\n    net = FIDEmbeddingNet(device=device)\n    embeddings = net.get_embeddings(dataloader)\n    return embeddings\n</code></pre>"},{"location":"api/#labproject.data.register_dataset","title":"<code>register_dataset(name)</code>","text":"<p>This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>Dataset generator function</p> required <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>Dataset generator function wrapper</p> Example <p>@register_dataset(\"random\") def random_dataset(n=1000, d=10):     return torch.randn(n, d)</p> Source code in <code>labproject/data.py</code> <pre><code>def register_dataset(name: str) -&gt; callable:\n    r\"\"\"This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.\n\n    Args:\n        func (callable): Dataset generator function\n\n    Returns:\n        callable: Dataset generator function wrapper\n\n    Example:\n        &gt;&gt;&gt; @register_dataset(\"random\")\n        &gt;&gt;&gt; def random_dataset(n=1000, d=10):\n        &gt;&gt;&gt;     return torch.randn(n, d)\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(n: int, d: Optional[int] = None, **kwargs):\n\n            assert n &gt; 0, \"n must be a positive integer\"\n            if d is not None:\n                assert d &gt; 0, \"d must be a positive integer\"\n            else:\n                warnings.warn(\"d is not specified, make sure you know what you're doing!\")\n\n            # Call the original function\n            dataset = func(n, d, **kwargs)\n\n            # Convert the dataset to a PyTorch tensor\n            dataset = torch.Tensor(dataset) if not isinstance(dataset, torch.Tensor) else dataset\n\n            assert dataset.shape == (n, d), f\"Dataset shape must be {(n, d)}\"\n\n            return dataset\n\n        DATASETS[name] = wrapper\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/#labproject.data.register_distribution","title":"<code>register_distribution(name)</code>","text":"<p>This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>Dataset generator function</p> required <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>Dataset generator function wrapper</p> Example <p>@register_dataset(\"random\") def random_dataset(n=1000, d=10):     return torch.randn(n, d)</p> Source code in <code>labproject/data.py</code> <pre><code>def register_distribution(name: str) -&gt; callable:\n    r\"\"\"This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.\n\n    Args:\n        func (callable): Dataset generator function\n\n    Returns:\n        callable: Dataset generator function wrapper\n\n    Example:\n        &gt;&gt;&gt; @register_dataset(\"random\")\n        &gt;&gt;&gt; def random_dataset(n=1000, d=10):\n        &gt;&gt;&gt;     return torch.randn(n, d)\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Call the original function\n            distribution = func(*args, **kwargs)\n            return distribution\n\n        DISTRIBUTIONS[name] = wrapper\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/#labproject.data.upload_file","title":"<code>upload_file(local_path, remote_path)</code>","text":"<p>Uploads a file to the Hetzner Storage Box.</p> <p>Parameters:</p> Name Type Description Default <code>local_path</code> <code>str</code> <p>The path to the local file to be uploaded.</p> required <code>remote_path</code> <code>str</code> <p>The path where the file should be uploaded on the remote server.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the upload is successful, False otherwise.</p> Example <p>if upload_file('path/to/your/local/file.txt', 'path/to/remote/file.txt'):     print(\"Upload successful\") else:     print(\"Upload failed\")</p> Source code in <code>labproject/data.py</code> <pre><code>def upload_file(local_path: str, remote_path: str):\n    r\"\"\"\n    Uploads a file to the Hetzner Storage Box.\n\n    Args:\n        local_path (str): The path to the local file to be uploaded.\n        remote_path (str): The path where the file should be uploaded on the remote server.\n\n    Returns:\n        bool: True if the upload is successful, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if upload_file('path/to/your/local/file.txt', 'path/to/remote/file.txt'):\n        &gt;&gt;&gt;     print(\"Upload successful\")\n        &gt;&gt;&gt; else:\n        &gt;&gt;&gt;     print(\"Upload failed\")\n    \"\"\"\n    url = f\"{STORAGEBOX_URL}/remote.php/dav/files/{HETZNER_STORAGEBOX_USERNAME}/{remote_path}\"\n    auth = HTTPBasicAuth(HETZNER_STORAGEBOX_USERNAME, HETZNER_STORAGEBOX_PASSWORD)\n    with open(local_path, \"rb\") as f:\n        data = f.read()\n    response = requests.put(url, data=data, auth=auth)\n    return response.status_code == 201\n</code></pre>"},{"location":"api/#embeddings","title":"Embeddings","text":"<p>This contains embedding nets, and auxilliary functions for extracting (N,D) embeddings from respective data and models.</p>"},{"location":"api/#experiments","title":"Experiments","text":""},{"location":"api/#labproject.experiments.ScaleDim","title":"<code>ScaleDim</code>","text":"<p>             Bases: <code>Experiment</code></p> Source code in <code>labproject/experiments.py</code> <pre><code>class ScaleDim(Experiment):\n    def __init__(self, metric_name, metric_fn, min_dim=1, max_dim=1000, step=100):\n        self.metric_name = metric_name\n        self.metric_fn = metric_fn\n        self.dimensionality = list(range(min_dim, max_dim, step))\n        super().__init__()\n\n    def run_experiment(self, dataset1, dataset2):\n        distances = []\n        for d in self.dimensionality:\n            distances.append(self.metric_fn(dataset1[:, :d], dataset2[:, :d]))\n        return self.dimensionality, distances\n\n    def plot_experiment(self, dimensionality, distances, dataset_name, ax=None):\n        plot_scaling_metric_dimensionality(\n            dimensionality, distances, self.metric_name, dataset_name, ax=ax\n        )\n\n    def log_results(self, results, log_path):\n        \"\"\"\n        Save the results to a file.\n        \"\"\"\n        with open(log_path, \"wb\") as f:\n            pickle.dump(results, f)\n</code></pre>"},{"location":"api/#labproject.experiments.ScaleDim.log_results","title":"<code>log_results(results, log_path)</code>","text":"<p>Save the results to a file.</p> Source code in <code>labproject/experiments.py</code> <pre><code>def log_results(self, results, log_path):\n    \"\"\"\n    Save the results to a file.\n    \"\"\"\n    with open(log_path, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"api/#labproject.experiments.ScaleSampleSize","title":"<code>ScaleSampleSize</code>","text":"<p>             Bases: <code>Experiment</code></p> Source code in <code>labproject/experiments.py</code> <pre><code>class ScaleSampleSize(Experiment):\n\n    def __init__(self, metric_name, metric_fn, min_samples=2, max_samples=1000, step=100):\n        assert min_samples &gt; 1, \"min_samples must be greater than 1\"\n        self.metric_name = metric_name\n        self.metric_fn = metric_fn\n        self.sample_sizes = list(range(min_samples, max_samples, step))\n        super().__init__()\n\n    def run_experiment(self, dataset1, dataset2):\n        distances = []\n        for n in self.sample_sizes:\n            distances.append(self.metric_fn(dataset1[:n, :], dataset2[:n, :]))\n        return self.sample_sizes, distances\n\n    def plot_experiment(\n        self, sample_sizes, distances, dataset_name, ax=None, color=None, label=None\n    ):\n        plot_scaling_metric_sample_size(\n            sample_sizes, distances, self.metric_name, dataset_name, ax=ax, color=color, label=label\n        )\n\n    def log_results(self, results, log_path):\n        \"\"\"\n        Save the results to a file.\n        \"\"\"\n        with open(log_path, \"wb\") as f:\n            pickle.dump(results, f)\n</code></pre>"},{"location":"api/#labproject.experiments.ScaleSampleSize.log_results","title":"<code>log_results(results, log_path)</code>","text":"<p>Save the results to a file.</p> Source code in <code>labproject/experiments.py</code> <pre><code>def log_results(self, results, log_path):\n    \"\"\"\n    Save the results to a file.\n    \"\"\"\n    with open(log_path, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"api/#plotting","title":"Plotting","text":""},{"location":"api/#labproject.plotting.plot_scaling_metric_dimensionality","title":"<code>plot_scaling_metric_dimensionality(dimensionality, distances, metric_name, dataset_name, ax=None)</code>","text":"<p>Plot the scaling of a metric with increasing dimensionality.</p> Source code in <code>labproject/plotting.py</code> <pre><code>def plot_scaling_metric_dimensionality(\n    dimensionality, distances, metric_name, dataset_name, ax=None\n):\n    \"\"\"Plot the scaling of a metric with increasing dimensionality.\"\"\"\n    if ax is None:\n        plt.plot(dimensionality, distances, label=metric_name)\n        plt.xlabel(\"Dimensionality\")\n        plt.ylabel(metric_name)\n        plt.title(f\"{metric_name} with increasing dimensionality for {dataset_name}\")\n        plt.savefig(\n            os.path.join(\n                PLOT_PATH,\n                f\"{metric_name.lower().replace(' ', '_')}_dimensionality_{dataset_name.lower().replace(' ', '_')}.png\",\n            )\n        )\n        plt.close()\n    else:\n        ax.plot(dimensionality, distances, label=metric_name)\n        ax.set_xlabel(\"Dimensionality\")\n\n        return ax\n</code></pre>"},{"location":"api/#labproject.plotting.plot_scaling_metric_sample_size","title":"<code>plot_scaling_metric_sample_size(sample_size, distances, metric_name, dataset_name, ax=None, color=None, label=None)</code>","text":"<p>Plot the behavior of a metric with number of samples.</p> Source code in <code>labproject/plotting.py</code> <pre><code>def plot_scaling_metric_sample_size(\n    sample_size, distances, metric_name, dataset_name, ax=None, color=None, label=None\n):\n    \"\"\"Plot the behavior of a metric with number of samples.\"\"\"\n    if ax is None:\n        if color is not None:\n            plt.plot(\n                sample_size, distances, color=color, label=metric_name if label is None else label\n            )\n        else:\n            plt.plot(sample_size, distances, label=metric_name)\n        plt.xlabel(\"samples\")\n        plt.ylabel(metric_name)\n        plt.title(f\"{metric_name} with increasing sample size for {dataset_name}\")\n        plt.savefig(\n            os.path.join(\n                PLOT_PATH,\n                f\"{metric_name.lower().replace(' ', '_')}_sample_size_{dataset_name.lower().replace(' ', '_')}.png\",\n            )\n        )\n        plt.close()\n    else:\n        if color is not None:\n            ax.plot(\n                sample_size, distances, color=color, label=metric_name if label is None else label\n            )\n        else:\n            ax.plot(sample_size, distances, label=metric_name if label is None else label)\n        ax.set_xlabel(\"samples\")\n\n        return ax\n</code></pre>"},{"location":"api/#utils","title":"Utils","text":""},{"location":"api/#labproject.utils.get_cfg","title":"<code>get_cfg()</code>","text":"<p>This function returns the configuration file for the current experiment run.</p> <p>The configuration file is expected to be located at ../configs/conf_{name}.yaml, where name will match the name of the run_{name}.py file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration file is not found</p> <p>Returns:</p> Name Type Description <code>OmegaConf</code> <code>OmegaConf</code> <p>Dictionary with the configuration parameters</p> Source code in <code>labproject/utils.py</code> <pre><code>def get_cfg() -&gt; OmegaConf:\n    \"\"\"This function returns the configuration file for the current experiment run.\n\n    The configuration file is expected to be located at ../configs/conf_{name}.yaml, where name will match the name of the run_{name}.py file.\n\n    Raises:\n        FileNotFoundError: If the configuration file is not found\n\n    Returns:\n        OmegaConf: Dictionary with the configuration parameters\n    \"\"\"\n    caller_frame = inspect.currentframe().f_back\n    filename = caller_frame.f_code.co_filename\n    name = filename.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n    try:\n        config = OmegaConf.load(CONF_PATH + f\"/conf_{name}.yaml\")\n        config.running_user = name\n    except FileNotFoundError:\n        msg = f\"Config file not found for {name}. Please create a config file at ../configs/conf_{name}.yaml\"\n        raise FileNotFoundError(msg)\n    return config\n</code></pre>"},{"location":"api/#labproject.utils.get_log_path","title":"<code>get_log_path(cfg)</code>","text":"<p>Get the log path for the current experiment run. This log path is then used to save the numerical results of the experiment. Import this function in the run_{name}.py file and call it to get the log path.</p> Source code in <code>labproject/utils.py</code> <pre><code>def get_log_path(cfg):\n    \"\"\"\n    Get the log path for the current experiment run.\n    This log path is then used to save the numerical results of the experiment.\n    Import this function in the run_{name}.py file and call it to get the log path.\n    \"\"\"\n\n    # get datetime string\n    now = datetime.datetime.now()\n    if \"exp_log_name\" not in cfg:\n        exp_log_name = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n    else:\n        exp_log_name = cfg.exp_log_name\n        # add datetime to the name\n        exp_log_name = exp_log_name + \"_\" + now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n    log_path = os.path.join(f\"results/{cfg.running_user}/{exp_log_name}.pkl\")\n    return log_path\n</code></pre>"},{"location":"api/#labproject.utils.set_seed","title":"<code>set_seed(seed)</code>","text":"<p>Set seed for reproducibility</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Integer seed</p> required Source code in <code>labproject/utils.py</code> <pre><code>def set_seed(seed: int) -&gt; None:\n    \"\"\"Set seed for reproducibility\n\n    Args:\n        seed (int): Integer seed\n    \"\"\"\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    return seed\n</code></pre>"},{"location":"notebooks/application1/","title":"Application1","text":"In\u00a0[190]: Copied! <pre>import torch\nimport numpy as np\nfrom torch import Tensor\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance\nfrom labproject.experiments import Experiment\n</pre> import torch import numpy as np from torch import Tensor import pandas as pd import matplotlib.pyplot as plt import seaborn as sns  from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance from labproject.experiments import Experiment  In\u00a0[191]: Copied! <pre>dataset1 = torch.load('../../data/cifar10_train.pt') # torch.Size([50000, 2048])\ndataset2 = torch.load('../../data/cifar10_test.pt') # torch.Size([10000, 2048])\n</pre>  dataset1 = torch.load('../../data/cifar10_train.pt') # torch.Size([50000, 2048]) dataset2 = torch.load('../../data/cifar10_test.pt') # torch.Size([10000, 2048]) In\u00a0[192]: Copied! <pre>class Metric:\n    def __init__(self, name: str, func: callable, **kwargs):\n        self.name = name\n        self.func = func\n        self.kwargs = kwargs\n\n    def __call__(self, x: Tensor, y: Tensor) -&gt; Tensor:\n        return self.func(x, y, **self.kwargs)\n\n\nclass DistComp(Experiment):\n    def __init__(self, dataset1: Tensor, dataset2: Tensor, metrics: list[Metric], \n                 n_perms: int = 100, perm_size=1000, descr=\"\"):\n        self.dataset1 = dataset1\n        self.dataset2 = dataset2\n        self.metrics = metrics\n        self.n_perms = n_perms\n        self.perm_size = perm_size\n        self.descr = descr\n\n        columns = [metric.name for metric in metrics]\n        self.results_df = pd.DataFrame(np.nan, index=range(self.n_perms), columns=columns)\n\n    def run_experiment(self):\n        for i in range(self.n_perms):\n            dataset2_perm = self.dataset2[torch.randperm(self.perm_size)]\n            dataset1_perm = self.dataset1[torch.randperm(self.perm_size)]\n            for metric in self.metrics:\n                self.results_df.loc[i, metric.name] = metric(dataset1_perm, dataset2_perm).numpy()\n\n    def plot_results(self):\n        pass\n</pre> class Metric:     def __init__(self, name: str, func: callable, **kwargs):         self.name = name         self.func = func         self.kwargs = kwargs      def __call__(self, x: Tensor, y: Tensor) -&gt; Tensor:         return self.func(x, y, **self.kwargs)   class DistComp(Experiment):     def __init__(self, dataset1: Tensor, dataset2: Tensor, metrics: list[Metric],                   n_perms: int = 100, perm_size=1000, descr=\"\"):         self.dataset1 = dataset1         self.dataset2 = dataset2         self.metrics = metrics         self.n_perms = n_perms         self.perm_size = perm_size         self.descr = descr          columns = [metric.name for metric in metrics]         self.results_df = pd.DataFrame(np.nan, index=range(self.n_perms), columns=columns)      def run_experiment(self):         for i in range(self.n_perms):             dataset2_perm = self.dataset2[torch.randperm(self.perm_size)]             dataset1_perm = self.dataset1[torch.randperm(self.perm_size)]             for metric in self.metrics:                 self.results_df.loc[i, metric.name] = metric(dataset1_perm, dataset2_perm).numpy()      def plot_results(self):         pass  In\u00a0[193]: Copied! <pre>metrics = [\n    Metric('sliced_wasserstein_distance', \n           sliced_wasserstein_distance,\n           num_projections=50,\n           p=2),\n    Metric('sliced_wasserstein_distance', \n           sliced_wasserstein_distance,\n           num_projections=50,\n           p=1),\n    Metric('sliced_wasserstein_distance', \n           sliced_wasserstein_distance,\n           num_projections=50,\n           p=1),\n]\n\nexperiments = [\n    DistComp(\n        dataset1, dataset1, metrics, n_perms=10, perm_size=1,\n        descr='unconditional within-group real data'\n    ),\n    DistComp(\n        dataset2, dataset2, metrics, n_perms=10, perm_size=1,\n        descr='unconditional within-group generated data'\n    ),\n    DistComp(\n        dataset1, dataset2, metrics, n_perms=10, perm_size=1,\n        descr='unconditional between-group'\n    ),\n]\n\nfor experiment in experiments:\n    experiment.run_experiment()\n</pre>  metrics = [     Metric('sliced_wasserstein_distance',             sliced_wasserstein_distance,            num_projections=50,            p=2),     Metric('sliced_wasserstein_distance',             sliced_wasserstein_distance,            num_projections=50,            p=1),     Metric('sliced_wasserstein_distance',             sliced_wasserstein_distance,            num_projections=50,            p=1), ]  experiments = [     DistComp(         dataset1, dataset1, metrics, n_perms=10, perm_size=1,         descr='unconditional within-group real data'     ),     DistComp(         dataset2, dataset2, metrics, n_perms=10, perm_size=1,         descr='unconditional within-group generated data'     ),     DistComp(         dataset1, dataset2, metrics, n_perms=10, perm_size=1,         descr='unconditional between-group'     ), ]  for experiment in experiments:     experiment.run_experiment()  In\u00a0[194]: Copied! <pre>for experiment in experiments:\n    print(f\"Plotting experiment: {experiment.descr}\")\n    print(experiment.results_df)\n    # experiment.plot_results()\n</pre> for experiment in experiments:     print(f\"Plotting experiment: {experiment.descr}\")     print(experiment.results_df)     # experiment.plot_results() <pre>Plotting experiment: unconditional within-group real data\n   sliced_wasserstein_distance  sliced_wasserstein_distance  \\\n0                          0.0                          0.0   \n1                          0.0                          0.0   \n2                          0.0                          0.0   \n3                          0.0                          0.0   \n4                          0.0                          0.0   \n5                          0.0                          0.0   \n6                          0.0                          0.0   \n7                          0.0                          0.0   \n8                          0.0                          0.0   \n9                          0.0                          0.0   \n\n   sliced_wasserstein_distance  \n0                          0.0  \n1                          0.0  \n2                          0.0  \n3                          0.0  \n4                          0.0  \n5                          0.0  \n6                          0.0  \n7                          0.0  \n8                          0.0  \n9                          0.0  \nPlotting experiment: unconditional within-group generated data\n   sliced_wasserstein_distance  sliced_wasserstein_distance  \\\n0                          0.0                          0.0   \n1                          0.0                          0.0   \n2                          0.0                          0.0   \n3                          0.0                          0.0   \n4                          0.0                          0.0   \n5                          0.0                          0.0   \n6                          0.0                          0.0   \n7                          0.0                          0.0   \n8                          0.0                          0.0   \n9                          0.0                          0.0   \n\n   sliced_wasserstein_distance  \n0                          0.0  \n1                          0.0  \n2                          0.0  \n3                          0.0  \n4                          0.0  \n5                          0.0  \n6                          0.0  \n7                          0.0  \n8                          0.0  \n9                          0.0  \nPlotting experiment: unconditional between-group\n   sliced_wasserstein_distance  sliced_wasserstein_distance  \\\n0                     0.251259                     0.251259   \n1                     0.251387                     0.251387   \n2                     0.286034                     0.286034   \n3                     0.291807                     0.291807   \n4                     0.238574                     0.238574   \n5                     0.241275                     0.241275   \n6                     0.301774                     0.301774   \n7                     0.282948                     0.282948   \n8                     0.278921                     0.278921   \n9                     0.223074                     0.223074   \n\n   sliced_wasserstein_distance  \n0                     0.251259  \n1                     0.251387  \n2                     0.286034  \n3                     0.291807  \n4                     0.238574  \n5                     0.241275  \n6                     0.301774  \n7                     0.282948  \n8                     0.278921  \n9                     0.223074  \n</pre>"},{"location":"notebooks/application2/","title":"Application2","text":"In\u00a0[\u00a0]: Copied! <pre># init\n</pre> # init In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/compare_swd_sinkhorn/","title":"Compare swd sinkhorn","text":"In\u00a0[161]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[162]: Copied! <pre>import torch\nfrom labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance\nfrom labproject.metrics.wasserstein_sinkhorn import sinkhorn_loss\nfrom labproject.metrics.gaussian_squared_wasserstein import gaussian_squared_w2_distance\n</pre> import torch from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance from labproject.metrics.wasserstein_sinkhorn import sinkhorn_loss from labproject.metrics.gaussian_squared_wasserstein import gaussian_squared_w2_distance    In\u00a0[163]: Copied! <pre>data = torch.randn((1000,2))\ndata2 = torch.randn((1000,2))\n\nprint(sliced_wasserstein_distance(data, data2,num_projections=500,p=2).item())\nprint(sinkhorn_loss(data, data2,epsilon=1e-3, niter=1000,p=2).item())\nprint(torch.sqrt(gaussian_squared_w2_distance(data, data2)).item())\n# print(wasserstein_munkres(data, data2,p=2).item())\n</pre> data = torch.randn((1000,2)) data2 = torch.randn((1000,2))  print(sliced_wasserstein_distance(data, data2,num_projections=500,p=2).item()) print(sinkhorn_loss(data, data2,epsilon=1e-3, niter=1000,p=2).item()) print(torch.sqrt(gaussian_squared_w2_distance(data, data2)).item()) # print(wasserstein_munkres(data, data2,p=2).item()) <pre>0.07661963999271393\n0.1118786375773585\n0.06996694207191467\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/example/","title":"Example notebook","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nnp.random.seed(0)\nimport matplotlib.pyplot as plt\n</pre> import numpy as np np.random.seed(0) import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>data = np.random.rand(100,2)\ndata.shape\n</pre> data = np.random.rand(100,2) data.shape Out[2]: <pre>(100, 2)</pre> In\u00a0[3]: Copied! <pre>plt.scatter(data[:,0], data[:,1])\n</pre> plt.scatter(data[:,0], data[:,1]) Out[3]: <pre>&lt;matplotlib.collections.PathCollection at 0x11bf91cd0&gt;</pre>"},{"location":"notebooks/example/#example-notebook","title":"Example notebook\u00b6","text":""},{"location":"notebooks/example/#create-data","title":"Create Data\u00b6","text":""},{"location":"notebooks/example/#visualize-data","title":"Visualize data\u00b6","text":""},{"location":"notebooks/fid/","title":"FID notebook","text":"In\u00a0[3]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[4]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import torch import torch.nn as nn import torch.nn.functional as F  import numpy as np import matplotlib.pyplot as plt  In\u00a0[5]: Copied! <pre>!pip install torchvision\n</pre> !pip install torchvision <pre>Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nCollecting torchvision\n  Downloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: numpy in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (1.26.3)\nRequirement already satisfied: requests in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch==2.2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (2.2.0)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (10.2.0)\nRequirement already satisfied: filelock in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions&gt;=4.8.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (4.9.0)\nRequirement already satisfied: sympy in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (1.12)\nRequirement already satisfied: networkx in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.1.3)\nRequirement already satisfied: fsspec in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2023.12.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch==2.2.0-&gt;torchvision) (12.3.101)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (2.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (2023.11.17)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from jinja2-&gt;torch==2.2.0-&gt;torchvision) (2.1.4)\nRequirement already satisfied: mpmath&gt;=0.19 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from sympy-&gt;torch==2.2.0-&gt;torchvision) (1.3.0)\nDownloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.9/6.9 MB 69.7 MB/s eta 0:00:00a 0:00:01\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.17.0\n</pre> In\u00a0[8]: Copied! <pre>import torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\n\ntransform = transforms.Compose([\n        transforms.Resize((299, 299)),\n        transforms.ToTensor(),\n        # normalize specific to inception model\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n# load CIFAR10 dataset\ncifar10_train = CIFAR10(root='/mnt_mount/labproject_data', train=True, download=True, transform=transform)\ncifar10_test = CIFAR10(root='/mnt_mount/labproject_data', train=False, download=True, transform=transform)\n</pre> import torchvision.transforms as transforms from torchvision.datasets import CIFAR10  transform = transforms.Compose([         transforms.Resize((299, 299)),         transforms.ToTensor(),         # normalize specific to inception model         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),     ])  # load CIFAR10 dataset cifar10_train = CIFAR10(root='/mnt_mount/labproject_data', train=True, download=True, transform=transform) cifar10_test = CIFAR10(root='/mnt_mount/labproject_data', train=False, download=True, transform=transform)  <pre>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt_mount/labproject_data/cifar-10-python.tar.gz\n</pre> <pre>100.0%\n</pre> <pre>Extracting /mnt_mount/labproject_data/cifar-10-python.tar.gz to /mnt_mount/labproject_data\nFiles already downloaded and verified\n</pre> In\u00a0[10]: Copied! <pre>dataloader_1 = torch.utils.data.DataLoader(cifar10_train, batch_size=100, shuffle=False, num_workers=1)\ndataloader_2 = torch.utils.data.DataLoader(cifar10_test, batch_size=100, shuffle=False, num_workers=1)\n</pre> dataloader_1 = torch.utils.data.DataLoader(cifar10_train, batch_size=100, shuffle=False, num_workers=1) dataloader_2 = torch.utils.data.DataLoader(cifar10_test, batch_size=100, shuffle=False, num_workers=1) In\u00a0[11]: Copied! <pre>from torchvision.models import inception_v3\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\n\n# get embedding net\ndef get_embedding_net():\n    model = inception_v3(pretrained=True)\n    model.fc = torch.nn.Identity()  # replace the classifier with identity to get features\n    model.eval()\n    return model.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n# extract features\ndef extract_features(dataloader, model):\n    features = []\n    with torch.no_grad():\n        for data, _ in dataloader:\n            data = data.to('cuda' if torch.cuda.is_available() else 'cpu')\n            features.append(model(data))\n    return torch.cat(features).cpu().numpy()\n\n\nembedding_net = get_embedding_net()\n\nfeatures1 = extract_features(dataloader_1, embedding_net)\nfeatures2 = extract_features(dataloader_2, embedding_net)\n</pre> from torchvision.models import inception_v3 from torchvision.datasets import ImageFolder from torch.utils.data import DataLoader import numpy as np   # get embedding net def get_embedding_net():     model = inception_v3(pretrained=True)     model.fc = torch.nn.Identity()  # replace the classifier with identity to get features     model.eval()     return model.to('cuda' if torch.cuda.is_available() else 'cpu')  # extract features def extract_features(dataloader, model):     features = []     with torch.no_grad():         for data, _ in dataloader:             data = data.to('cuda' if torch.cuda.is_available() else 'cpu')             features.append(model(data))     return torch.cat(features).cpu().numpy()   embedding_net = get_embedding_net()  features1 = extract_features(dataloader_1, embedding_net) features2 = extract_features(dataloader_2, embedding_net)  <pre>/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\n</pre> In\u00a0[12]: Copied! <pre>features1.shape, features2.shape\n</pre> features1.shape, features2.shape Out[12]: <pre>((50000, 2048), (10000, 2048))</pre> In\u00a0[16]: Copied! <pre>from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance\n\nswd = sliced_wasserstein_distance(torch.from_numpy(features1)[:10000], torch.from_numpy(features2), num_projections=1000)\n</pre> from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance  swd = sliced_wasserstein_distance(torch.from_numpy(features1)[:10000], torch.from_numpy(features2), num_projections=1000) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/wasserstein_intuition/","title":"Wasserstein intuition","text":"In\u00a0[110]: Copied! <pre>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom labproject.metrics.wasserstein_sinkhorn import sinkhorn_loss,sinkhorn_algorithm\nfrom labproject.data import get_distribution\nfrom labproject.utils import set_seed\n\nset_seed(0)\nplt.rcParams['figure.dpi'] = 150\n</pre> import torch import numpy as np import matplotlib.pyplot as plt from labproject.metrics.wasserstein_sinkhorn import sinkhorn_loss,sinkhorn_algorithm from labproject.data import get_distribution from labproject.utils import set_seed  set_seed(0) plt.rcParams['figure.dpi'] = 150  In\u00a0[111]: Copied! <pre>toy_data = get_distribution(\"toy_2d\")\ndatagen = toy_data()\ndata = datagen.sample(1000)\n\ndef update_toy_mog(datagen,means,covs,weights):\n    datagen.means = means\n    datagen.covs = covs\n    datagen.weights = weights\n\n    datagen.gaussians = [\n        torch.distributions.MultivariateNormal(mean, covariance)\n        for mean, covariance in zip(datagen.means, datagen.covariances)\n    ]    \n    return datagen\n\nmeans2 = torch.Tensor([\n            [0.0, 2.5],\n            [-1.0, -0.5],\n            [1.0, -2.0],\n            [-2.0, -1.0],\n        ])\n            \ncovariances2 = torch.tensor(\n                        [\n                            [[1.0, 0.2], [0.2, 1.0]],\n                            [[1.0, -0.7], [-0.7, 1.0]],\n                            [[1.0, 0.0], [0.0, 1.0]],\n                            [[0.5, 0.0], [0.0, 0.5]],\n                        ]\n                        )\nweights2 = torch.tensor([0.3, 0.2, 0.1, 0.5])\ndatagen2 = update_toy_mog(datagen,means2,covariances2,weights2)\ndata2 = datagen2.sample(1000)\n</pre> toy_data = get_distribution(\"toy_2d\") datagen = toy_data() data = datagen.sample(1000)  def update_toy_mog(datagen,means,covs,weights):     datagen.means = means     datagen.covs = covs     datagen.weights = weights      datagen.gaussians = [         torch.distributions.MultivariateNormal(mean, covariance)         for mean, covariance in zip(datagen.means, datagen.covariances)     ]         return datagen  means2 = torch.Tensor([             [0.0, 2.5],             [-1.0, -0.5],             [1.0, -2.0],             [-2.0, -1.0],         ])              covariances2 = torch.tensor(                         [                             [[1.0, 0.2], [0.2, 1.0]],                             [[1.0, -0.7], [-0.7, 1.0]],                             [[1.0, 0.0], [0.0, 1.0]],                             [[0.5, 0.0], [0.0, 0.5]],                         ]                         ) weights2 = torch.tensor([0.3, 0.2, 0.1, 0.5]) datagen2 = update_toy_mog(datagen,means2,covariances2,weights2) data2 = datagen2.sample(1000) In\u00a0[112]: Copied! <pre>def highlight_cell(x,y, ax=None, **kwargs):\n    rect = plt.Rectangle((x-.5, y-.5), 1,1, fill=False, **kwargs)\n    ax = ax or plt.gca()\n    ax.add_patch(rect)\n    return rect\n</pre> def highlight_cell(x,y, ax=None, **kwargs):     rect = plt.Rectangle((x-.5, y-.5), 1,1, fill=False, **kwargs)     ax = ax or plt.gca()     ax.add_patch(rect)     return rect In\u00a0[118]: Copied! <pre>plot_data = data[:10]\nplot_data2 = data2[:10]\npairdist = torch.cdist(plot_data,plot_data2)\n\nfig,axs = plt.subplots(1,2,figsize=(10,5))\ncolors = axs[1].imshow(pairdist)\naxs[1].set_xticks(np.arange(len(pairdist[:,0])),labels=['$x_{}$'.format(i) for i in range(10)])\naxs[1].set_yticks(np.arange(len(pairdist[:,0])),labels=['$y_{}$'.format(i) for i in range(10)])\nfor i in range(10):\n    highlight_cell(i,i,ax=axs[1],color=\"r\",alpha=0.5)\ncbar = fig.colorbar(colors, ax=axs[1], location='right')\n\n\n\n\naxs[0].scatter(plot_data[:, 0], plot_data[:, 1])\naxs[0].scatter(plot_data2[:, 0], plot_data2[:, 1])\naxs[0].set_xlim(-5,5)\naxs[0].set_ylim(-5,5)\nindices = torch.arange(0,len(plot_data))\nfor ind,p1,p2 in zip(indices,plot_data,plot_data2):\n    axs[0].arrow(p1[0],p1[1],p2[0]-p1[0],p2[1]-p1[1],head_width=0.2, head_length=0.2,length_includes_head=True,color = cbar.cmap(pairdist[ind,ind].item()/pairdist.max().item()))\n</pre> plot_data = data[:10] plot_data2 = data2[:10] pairdist = torch.cdist(plot_data,plot_data2)  fig,axs = plt.subplots(1,2,figsize=(10,5)) colors = axs[1].imshow(pairdist) axs[1].set_xticks(np.arange(len(pairdist[:,0])),labels=['$x_{}$'.format(i) for i in range(10)]) axs[1].set_yticks(np.arange(len(pairdist[:,0])),labels=['$y_{}$'.format(i) for i in range(10)]) for i in range(10):     highlight_cell(i,i,ax=axs[1],color=\"r\",alpha=0.5) cbar = fig.colorbar(colors, ax=axs[1], location='right')     axs[0].scatter(plot_data[:, 0], plot_data[:, 1]) axs[0].scatter(plot_data2[:, 0], plot_data2[:, 1]) axs[0].set_xlim(-5,5) axs[0].set_ylim(-5,5) indices = torch.arange(0,len(plot_data)) for ind,p1,p2 in zip(indices,plot_data,plot_data2):     axs[0].arrow(p1[0],p1[1],p2[0]-p1[0],p2[1]-p1[1],head_width=0.2, head_length=0.2,length_includes_head=True,color = cbar.cmap(pairdist[ind,ind].item()/pairdist.max().item()))   In\u00a0[119]: Copied! <pre>cmap = cbar.cmap\nprint(cmap(pairdist[0,0]))\n</pre> cmap = cbar.cmap print(cmap(pairdist[0,0])) <pre>(0.993248, 0.906157, 0.143936, 1.0)\n</pre> In\u00a0[120]: Copied! <pre>permutation = torch.randperm(plot_data2.size()[0])\nplot_data2 = plot_data2[permutation]\n#pairdist = torch.cdist(plot_data,plot_data2)\n\nfig,axs = plt.subplots(1,2,figsize=(10,5))\n\ncolors = axs[1].imshow(pairdist)\naxs[1].set_xticks(np.arange(len(pairdist[:,0])),labels=['$x_{}$'.format(i) for i in range(10)])\naxs[1].set_yticks(np.arange(len(pairdist[:,0])),labels=['$y_{}$'.format(i) for i in range(10)])\nfor i in range(10):\n    highlight_cell(i,permutation[i],ax=axs[1],color=\"r\",alpha=0.5)\ncbar = fig.colorbar(colors, ax=axs[1], location='right')\n\n\n\n\naxs[0].scatter(plot_data[:, 0], plot_data[:, 1])\naxs[0].scatter(plot_data2[:, 0], plot_data2[:, 1])\naxs[0].set_xlim(-5,5)\naxs[0].set_ylim(-5,5)\nindices = torch.arange(0,len(plot_data))\nfor ind,p1,p2 in zip(indices,plot_data,plot_data2):\n    axs[0].arrow(p1[0],p1[1],p2[0]-p1[0],p2[1]-p1[1],head_width=0.2, head_length=0.2,length_includes_head=True,color = cbar.cmap(pairdist[ind,permutation[ind]].item()/pairdist.max().item()))\n</pre> permutation = torch.randperm(plot_data2.size()[0]) plot_data2 = plot_data2[permutation] #pairdist = torch.cdist(plot_data,plot_data2)  fig,axs = plt.subplots(1,2,figsize=(10,5))  colors = axs[1].imshow(pairdist) axs[1].set_xticks(np.arange(len(pairdist[:,0])),labels=['$x_{}$'.format(i) for i in range(10)]) axs[1].set_yticks(np.arange(len(pairdist[:,0])),labels=['$y_{}$'.format(i) for i in range(10)]) for i in range(10):     highlight_cell(i,permutation[i],ax=axs[1],color=\"r\",alpha=0.5) cbar = fig.colorbar(colors, ax=axs[1], location='right')     axs[0].scatter(plot_data[:, 0], plot_data[:, 1]) axs[0].scatter(plot_data2[:, 0], plot_data2[:, 1]) axs[0].set_xlim(-5,5) axs[0].set_ylim(-5,5) indices = torch.arange(0,len(plot_data)) for ind,p1,p2 in zip(indices,plot_data,plot_data2):     axs[0].arrow(p1[0],p1[1],p2[0]-p1[0],p2[1]-p1[1],head_width=0.2, head_length=0.2,length_includes_head=True,color = cbar.cmap(pairdist[ind,permutation[ind]].item()/pairdist.max().item()))   In\u00a0[\u00a0]: Copied! <pre>cost,transport = sinkhorn_algorithm(plot_data,plot_data2,eps=0.1,return_transport=True)\n</pre> cost,transport = sinkhorn_algorithm(plot_data,plot_data2,eps=0.1,return_transport=True)"}]}