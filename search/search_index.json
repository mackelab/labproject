{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A Practical Guide to Statistical Distances for Evaluating Generative Models in Science","text":"<p>Generative models are highly useful in many disciplines of science. How do we evaluate them? As the data generated by these models is often high-dimensional and/or non-parametric, we can typically not resort to classical statistical tests. This paper aims to provide an accessible entry point to a understanding popular statistical distances proposed and adopted by the machine learning in science community, requiring only foundational knowledge in mathematics or statistics. We focus on four commonly used classes of statistical distances: obtaining a distance using classifiers (e.g. classifier two-sample tests), using embeddings through kernels (e.g. Maximum Mean Discrepancy) or neural networks (e.g. Frechet Inception Distance), and slicing (e.g. sliced Wasserstein). We highlight their merits, scalability, complexity and pitfalls, which are all illustrated in accompanying notebooks. We then apply each metric to multiple examples generative models in scientific applications, spanning image generation, neuroscience... . We this aim to empower researchers to use, critically assess and interpret statistical distances for generative models in science.</p>"},{"location":"#installation","title":"Installation","text":"<p>Please execute the following commands in your terminal to install the labproject package and its dependencies. We recommend using a conda environment to avoid conflicts with other packages.</p> <pre><code># clone the repository\ngit clone https://github.com/mackelab/labproject.git\n\n# (optional but recommended) create conda environment\nconda create -n labproject python=3.9\nconda activate labproject\n\n# install labproject package with dependencies\npython3 -m pip install --upgrade pip\ncd labproject\npip install -e \".[dev,docs]\"\n\n# install pre-commit hooks for black auto-formatting\npre-commit install\n</code></pre> <p><code>pip install -e .</code> installs the labproject package in editable mode, i.e. changes to the code are immediately reflected in the package.</p> <p>The environment now contains, <code>numpy</code>, <code>scipy</code>, <code>matplotlib</code>, <code>torch</code>, and <code>jupyter</code>.</p>"},{"location":"#development","title":"Development","text":"<p>Develop code in your desired way, e.g. in local notebooks (you don't commit them, they will be automatically ignored). The public notebooks i.e. for the website can be found in <code>docs/notebooks/</code>, if you want to share the whole notebook then move it in this directory.</p>"},{"location":"#metrics","title":"Metrics","text":"<p>If you implemented a well-documented and reliable function that computes a metric, then move it to in <code>labproject/metrics</code> simply by add a new file <code>my_metric.py</code>.</p>"},{"location":"#plotting","title":"Plotting","text":"<p>If you implemented a nice plotting function, then move it to in <code>labproject/plotting.py</code>. Especially if it is applicable to multiple tasks.</p>"},{"location":"#running-experiments","title":"Running experiments","text":"<p>After committing and pushing your changes, GitHub will execute every <code>run_{name}.py</code> and update the figures in Overleaf. </p> <p>You can also run it yourself with <code>python labproject/run_{name}.py</code>. Any results, will however not be pushed into the repository.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>We use mkdocs to create the public version of our tutorials (notebooks) and the API documentation. mkdocs are written in Markdown and are found in <code>docs/</code>.</p> <p>After installing the necessary dependencies with <code>pip install -e \".[docs]\"</code>, you can view your local version with <code>mkdocs serve</code> in <code>labproject/</code> and then open http://127.0.0.1:8000/. Every push to the main branch will also publish the current version on: http://www.mackelab.org/labproject/ </p> <p>To add your notebooks as pages in the docs, add the following to <code>mkdocs.yml</code>: <pre><code>pages:\n  - Notebooks: \n    - Example Notebook: notebooks/example.ipynb\n    - FID notebook: notebooks/fid.ipynb\n    - UR_NOTEBOOK_NAME: notebook/UR_NOTEBOOK_FILE\n</code></pre></p> <p>To add your functions to the API documentation, add the following to <code>docs/api.md</code>: <pre><code>### Your module\n::: labproject.your_module\n    options:\n      heading_level: 4\n</code></pre> To build it locally use <code>mkdocs build</code> (or <code>mkdocs serve</code> to view it locally). After pushing to the main branch, the documentation will be automatically updated.</p> <p>For adding new pages, create a new markdown file in <code>docs/</code> and add it to <code>mkdocs.yml</code>: <pre><code>pages:\n  - 'your_new_page.md'\n</code></pre></p> <p>Every docstring in the code will be automatically added to the API documentation. We will use \"Google Style\" docstrings, see here for an example.</p>"},{"location":"#notebooks","title":"Notebooks","text":"<p>The jupyter notebooks are found in <code>docs/notebooks/</code>.</p> <p>For your convenience, at the beginning of the jupyter notebook, run   <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> for automatic reloading of modules, in case you make any running changes to the labproject code.</p>"},{"location":"api/","title":"API reference for development package labproject","text":"<p>Here all functions will be documented that are part of the public API of the labproject package.</p>"},{"location":"api/#metrics","title":"Metrics","text":""},{"location":"api/#gaussian-kl-divergence","title":"Gaussian KL divergence","text":""},{"location":"api/#labproject.metrics.gaussian_kl.gaussian_kl_divergence","title":"<code>gaussian_kl_divergence(real_samples, fake_samples)</code>","text":"<p>Compute the KL divergence between Gaussian approximations of real and fake samples. Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).</p> <p>In detail, for each set of samples, we calculate the mean and covariance matrix.</p> \\[ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i \\] \\[ \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T \\] <p>Then we calculate the KL divergence between the two Gaussian approximations:</p> \\[ D_{KL}(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}) || N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) = \\frac{1}{2} \\left( \\text{tr}(\\Sigma_{\\text{fake}}^{-1} \\Sigma_{\\text{real}}) + (\\mu_{\\text{fake}} - \\mu_{\\text{real}})^T \\Sigma_{\\text{fake}}^{-1} (\\mu_{\\text{fake}} - \\mu_{\\text{real}}) - k + \\log \\frac{|\\Sigma_{\\text{fake}}|}{|\\Sigma_{\\text{real}}|} \\right) \\] <p>Parameters:</p> Name Type Description Default <code>real_samples</code> <code>Tensor</code> <p>A tensor representing the real samples.</p> required <code>fake_samples</code> <code>Tensor</code> <p>A tensor representing the fake samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The KL divergence between the two Gaussian approximations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; kl_div = gaussian_kl_divergence(real_samples, fake_samples)\n&gt;&gt;&gt; print(kl_div)\n</code></pre> Source code in <code>labproject/metrics/gaussian_kl.py</code> <pre><code>def gaussian_kl_divergence(real_samples: Tensor, fake_samples: Tensor) -&gt; Tensor:\n    r\"\"\"\n    Compute the KL divergence between Gaussian approximations of real and fake samples.\n    Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).\n\n    In detail, for each set of samples, we calculate the mean and covariance matrix.\n\n    $$ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n\n\n    $$\n    \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad\n    \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T\n    $$\n\n    Then we calculate the KL divergence between the two Gaussian approximations:\n\n    $$\n    D_{KL}(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}) || N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) =\n    \\frac{1}{2} \\left( \\text{tr}(\\Sigma_{\\text{fake}}^{-1} \\Sigma_{\\text{real}}) + (\\mu_{\\text{fake}} - \\mu_{\\text{real}})^T \\Sigma_{\\text{fake}}^{-1} (\\mu_{\\text{fake}} - \\mu_{\\text{real}})\n    - k + \\log \\frac{|\\Sigma_{\\text{fake}}|}{|\\Sigma_{\\text{real}}|} \\right)\n    $$\n\n    Args:\n        real_samples (torch.Tensor): A tensor representing the real samples.\n        fake_samples (torch.Tensor): A tensor representing the fake samples.\n\n    Returns:\n        torch.Tensor: The KL divergence between the two Gaussian approximations.\n\n    Examples:\n        &gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; kl_div = gaussian_kl_divergence(real_samples, fake_samples)\n        &gt;&gt;&gt; print(kl_div)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(real_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(fake_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    # calculate mean and covariance of real and fake samples\n    mu_real = real_samples.mean(dim=0)\n    mu_fake = fake_samples.mean(dim=0)\n    cov_real = torch.cov(real_samples.t())\n    cov_fake = torch.cov(fake_samples.t())\n\n    # ensure the covariance matrices are invertible\n    eps = 1e-8\n    cov_real += torch.eye(cov_real.size(0)) * eps\n    cov_fake += torch.eye(cov_fake.size(0)) * eps\n\n    # compute KL divergence\n    inv_cov_fake = torch.inverse(cov_fake)\n    kl_div = 0.5 * (\n        torch.trace(inv_cov_fake @ cov_real)\n        + (mu_fake - mu_real).dot(inv_cov_fake @ (mu_fake - mu_real))\n        - real_samples.size(1)\n        + torch.log(torch.det(cov_fake) / torch.det(cov_real))\n    )\n\n    return kl_div\n</code></pre>"},{"location":"api/#gaussian-wasserstein","title":"Gaussian Wasserstein","text":""},{"location":"api/#labproject.metrics.gaussian_squared_wasserstein.gaussian_squared_w2_distance","title":"<code>gaussian_squared_w2_distance(real_samples, fake_samples)</code>","text":"<p>Compute the squared Wasserstein distance between Gaussian approximations of real and fake samples. Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).</p> <p>In detail, for each set of samples, we calculate the mean and covariance matrix.</p> \\[ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i \\] \\[ \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T \\] <p>Then we calculate the squared Wasserstein distance between the two Gaussian approximations:</p> \\[ d_{W_2}^2(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}), N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) = \\left\\| \\mu_{\\text{real}} - \\mu_{\\text{fake}} \\right\\|^2 + \\text{tr}(\\Sigma_{\\text{real}} + \\Sigma_{\\text{fake}} - 2 \\sqrt{\\Sigma_{\\text{real}} \\Sigma_{\\text{fake}}}) \\] <p>Parameters:</p> Name Type Description Default <code>real_samples</code> <code>Tensor</code> <p>A tensor representing the real samples.</p> required <code>fake_samples</code> <code>Tensor</code> <p>A tensor representing the fake samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The KL divergence between the two Gaussian approximations.</p> References <p>[1] https://en.wikipedia.org/wiki/Wasserstein_metric [2] https://arxiv.org/pdf/1706.08500.pdf</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n&gt;&gt;&gt; w2 = gaussian_squared_w2_distance(real_samples, fake_samples)\n&gt;&gt;&gt; print(w2)\n</code></pre> Source code in <code>labproject/metrics/gaussian_squared_wasserstein.py</code> <pre><code>def gaussian_squared_w2_distance(real_samples: Tensor, fake_samples: Tensor) -&gt; Tensor:\n    r\"\"\"\n    Compute the squared Wasserstein distance between Gaussian approximations of real and fake samples.\n    Dimensionality of the samples must be the same and &gt;=2 (for covariance calculation).\n\n    In detail, for each set of samples, we calculate the mean and covariance matrix.\n\n    $$ \\mu_{\\text{real}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\qquad \\mu_{\\text{fake}} = \\frac{1}{n} \\sum_{i=1}^{n} y_i $$\n\n\n    $$\n    \\Sigma_{\\text{real}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu_{\\text{real}})(x_i - \\mu_{\\text{real}})^T \\qquad\n    \\Sigma_{\\text{fake}} = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\mu_{\\text{fake}})(y_i - \\mu_{\\text{fake}})^T\n    $$\n\n    Then we calculate the squared Wasserstein distance between the two Gaussian approximations:\n\n    $$\n    d_{W_2}^2(N(\\mu_{\\text{real}}, \\Sigma_{\\text{real}}), N(\\mu_{\\text{fake}}, \\Sigma_{\\text{fake}})) =\n    \\left\\| \\mu_{\\text{real}} - \\mu_{\\text{fake}} \\right\\|^2 + \\text{tr}(\\Sigma_{\\text{real}} + \\Sigma_{\\text{fake}} - 2 \\sqrt{\\Sigma_{\\text{real}} \\Sigma_{\\text{fake}}})\n    $$\n\n    Args:\n        real_samples (torch.Tensor): A tensor representing the real samples.\n        fake_samples (torch.Tensor): A tensor representing the fake samples.\n\n    Returns:\n        torch.Tensor: The KL divergence between the two Gaussian approximations.\n\n    References:\n        [1] https://en.wikipedia.org/wiki/Wasserstein_metric\n        [2] https://arxiv.org/pdf/1706.08500.pdf\n\n    Examples:\n        &gt;&gt;&gt; real_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; fake_samples = torch.randn(100, 2)  # 100 samples, 2-dimensional\n        &gt;&gt;&gt; w2 = gaussian_squared_w2_distance(real_samples, fake_samples)\n        &gt;&gt;&gt; print(w2)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(real_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(fake_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    # calculate mean and covariance of real and fake samples\n    mu_real = real_samples.mean(dim=0)\n    mu_fake = fake_samples.mean(dim=0)\n    cov_real = torch.cov(real_samples.t())\n    cov_fake = torch.cov(fake_samples.t())\n\n    # ensure the covariance matrices are invertible\n    eps = 1e-8\n    cov_real += torch.eye(cov_real.size(0)) * eps\n    cov_fake += torch.eye(cov_fake.size(0)) * eps\n\n    # compute KL divergence\n    mean_dist = torch.norm(mu_real - mu_fake, p=2)\n    cov_dist = torch.trace(cov_real + cov_fake - 2 * torch.linalg.cholesky(cov_real @ cov_fake))\n    w2_squared_dist = mean_dist**2 + cov_dist\n\n    return w2_squared_dist\n</code></pre>"},{"location":"api/#sliced-wasserstein","title":"Sliced Wasserstein","text":""},{"location":"api/#labproject.metrics.sliced_wasserstein.rand_projections","title":"<code>rand_projections(embedding_dim, num_samples)</code>","text":"<p>This function generates num_samples random samples from the latent space's unti sphere.r</p> <p>Parameters:</p> Name Type Description Default <code>embedding_dim</code> <code>int</code> <p>dimention of the embedding</p> required <code>sum_samples</code> <code>int</code> <p>number of samples</p> required Return <p>torch.tensor: tensor of size (num_samples, embedding_dim)</p> Source code in <code>labproject/metrics/sliced_wasserstein.py</code> <pre><code>def rand_projections(embedding_dim: int, num_samples: int):\n    \"\"\"\n    This function generates num_samples random samples from the latent space's unti sphere.r\n\n    Args:\n        embedding_dim (int): dimention of the embedding\n        sum_samples (int): number of samples\n\n    Return :\n        torch.tensor: tensor of size (num_samples, embedding_dim)\n    \"\"\"\n\n    ws = torch.randn((num_samples, embedding_dim))\n    projection = ws / torch.norm(ws, dim=-1, keepdim=True)\n    return projection\n</code></pre>"},{"location":"api/#labproject.metrics.sliced_wasserstein.sliced_wasserstein_distance","title":"<code>sliced_wasserstein_distance(encoded_samples, distribution_samples, num_projections=50, p=2, device='cpu')</code>","text":"<p>Sliced Wasserstein distance between encoded samples and distribution samples</p> <p>Parameters:</p> Name Type Description Default <code>encoded_samples</code> <code>Tensor</code> <p>tensor of encoded training samples</p> required <code>distribution_samples</code> <code>Tensor</code> <p>tensor drawn from the prior distribution</p> required <code>num_projection</code> <code>int</code> <p>number of projections to approximate sliced wasserstein distance</p> required <code>p</code> <code>int</code> <p>power of distance metric</p> <code>2</code> <code>device</code> <code>device</code> <p>torch device 'cpu' or 'cuda' gpu</p> <code>'cpu'</code> Return <p>torch.Tensor: Tensor of wasserstein distances of size (num_projections, 1)</p> Source code in <code>labproject/metrics/sliced_wasserstein.py</code> <pre><code>def sliced_wasserstein_distance(\n    encoded_samples: Tensor,\n    distribution_samples: Tensor,\n    num_projections: int = 50,\n    p: int = 2,\n    device: str = \"cpu\",\n):\n    \"\"\"\n    Sliced Wasserstein distance between encoded samples and distribution samples\n\n    Args:\n        encoded_samples (torch.Tensor): tensor of encoded training samples\n        distribution_samples (torch.Tensor): tensor drawn from the prior distribution\n        num_projection (int): number of projections to approximate sliced wasserstein distance\n        p (int): power of distance metric\n        device (torch.device): torch device 'cpu' or 'cuda' gpu\n\n    Return:\n        torch.Tensor: Tensor of wasserstein distances of size (num_projections, 1)\n    \"\"\"\n\n    # check input (n,d only)\n    assert len(encoded_samples.size()) == 2, \"Real samples must be 2-dimensional, (n,d)\"\n    assert len(distribution_samples.size()) == 2, \"Fake samples must be 2-dimensional, (n,d)\"\n\n    embedding_dim = distribution_samples.size(-1)\n\n    projections = rand_projections(embedding_dim, num_projections).to(device)\n\n    encoded_projections = encoded_samples.matmul(projections.transpose(-2, -1))\n\n    distribution_projections = distribution_samples.matmul(projections.transpose(-2, -1))\n\n    wasserstein_distance = (\n        torch.sort(encoded_projections.transpose(-2, -1), dim=-1)[0]\n        - torch.sort(distribution_projections.transpose(-2, -1), dim=-1)[0]\n    )\n\n    wasserstein_distance = torch.pow(torch.abs(wasserstein_distance), p)\n\n    # NOTE: currently computes the \"squared\" wasserstein distance\n    # No p-th root is applied\n\n    # return torch.pow(torch.mean(wasserstein_distance, dim=(-2, -1)), 1 / p)\n    return torch.mean(wasserstein_distance, dim=(-2, -1))\n</code></pre>"},{"location":"api/#main-modules","title":"Main Modules","text":""},{"location":"api/#data","title":"Data","text":""},{"location":"api/#labproject.data.download_file","title":"<code>download_file(remote_path, local_path)</code>","text":"<p>Downloads a file from the Hetzner Storage Box.</p> <p>Parameters:</p> Name Type Description Default <code>remote_path</code> <code>str</code> <p>The path to the remote file to be downloaded.</p> required <code>local_path</code> <code>str</code> <p>The path where the file should be saved locally.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the download is successful, False otherwise.</p> Example <p>if download_file('path/to/remote/file.txt', 'path/to/save/file.txt'):     print(\"Download successful\") else:     print(\"Download failed\")</p> Source code in <code>labproject/data.py</code> <pre><code>def download_file(remote_path, local_path):\n    r\"\"\"\n    Downloads a file from the Hetzner Storage Box.\n\n    Args:\n        remote_path (str): The path to the remote file to be downloaded.\n        local_path (str): The path where the file should be saved locally.\n\n    Returns:\n        bool: True if the download is successful, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if download_file('path/to/remote/file.txt', 'path/to/save/file.txt'):\n        &gt;&gt;&gt;     print(\"Download successful\")\n        &gt;&gt;&gt; else:\n        &gt;&gt;&gt;     print(\"Download failed\")\n    \"\"\"\n    url = f\"{STORAGEBOX_URL}/remote.php/dav/files/{HETZNER_STORAGEBOX_USERNAME}/{remote_path}\"\n    auth = HTTPBasicAuth(HETZNER_STORAGEBOX_USERNAME, HETZNER_STORAGEBOX_PASSWORD)\n    response = requests.get(url, auth=auth)\n    if response.status_code == 200:\n        with open(local_path, \"wb\") as f:\n            f.write(response.content)\n        return True\n    return False\n</code></pre>"},{"location":"api/#labproject.data.get_dataset","title":"<code>get_dataset(name)</code>","text":"<p>Get a dataset by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset</p> required <code>n</code> <code>int</code> <p>Number of samples</p> required <code>d</code> <code>int</code> <p>Dimensionality of the samples</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Dataset</p> Source code in <code>labproject/data.py</code> <pre><code>def get_dataset(name: str) -&gt; torch.Tensor:\n    r\"\"\"Get a dataset by name\n\n    Args:\n        name (str): Name of the dataset\n        n (int): Number of samples\n        d (int): Dimensionality of the samples\n\n    Returns:\n        torch.Tensor: Dataset\n    \"\"\"\n    assert name in DATASETS, f\"Dataset {name} not found, please register it first \"\n    return DATASETS[name]\n</code></pre>"},{"location":"api/#labproject.data.get_distribution","title":"<code>get_distribution(name)</code>","text":"<p>Get a distribution by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the distribution</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Distribution</p> Source code in <code>labproject/data.py</code> <pre><code>def get_distribution(name: str) -&gt; torch.Tensor:\n    r\"\"\"Get a distribution by name\n\n    Args:\n        name (str): Name of the distribution\n\n    Returns:\n        torch.Tensor: Distribution\n    \"\"\"\n    assert name in DISTRIBUTIONS, f\"Distribution {name} not found, please register it first \"\n    return DISTRIBUTIONS[name]\n</code></pre>"},{"location":"api/#labproject.data.load_cifar10","title":"<code>load_cifar10(n, save_path='data', train=True, batch_size=100, shuffle=False, num_workers=1, device='cpu')</code>","text":"<p>Load a subset of cifar10</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of samples to load</p> required <code>save_path</code> <code>str</code> <p>Path to save files. Defaults to \"data\".</p> <code>'data'</code> <code>train</code> <code>bool</code> <p>Train or test. Defaults to True.</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>Batch size. Defaults to 100.</p> <code>100</code> <code>shuffle</code> <code>bool</code> <p>Shuffle. Defaults to False.</p> <code>False</code> <code>num_workers</code> <code>int</code> <p>Parallel workers. Defaults to 1.</p> <code>1</code> <code>device</code> <code>str</code> <p>Device. Defaults to \"cpu\".</p> <code>'cpu'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Cifar10 embeddings</p> Source code in <code>labproject/data.py</code> <pre><code>def load_cifar10(\n    n: int, save_path=\"data\", train=True, batch_size=100, shuffle=False, num_workers=1, device=\"cpu\"\n) -&gt; torch.Tensor:\n    \"\"\"Load a subset of cifar10\n\n    Args:\n        n (int): Number of samples to load\n        save_path (str, optional): Path to save files. Defaults to \"data\".\n        train (bool, optional): Train or test. Defaults to True.\n        batch_size (int, optional): Batch size. Defaults to 100.\n        shuffle (bool, optional): Shuffle. Defaults to False.\n        num_workers (int, optional): Parallel workers. Defaults to 1.\n        device (str, optional): Device. Defaults to \"cpu\".\n\n    Returns:\n        torch.Tensor: Cifar10 embeddings\n    \"\"\"\n    transform = transforms.Compose(\n        [\n            transforms.Resize((299, 299)),\n            transforms.ToTensor(),\n            # normalize specific to inception model\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            # Move to GPU if available\n            transforms.Lambda(lambda x: x.to(device if torch.cuda.is_available() else \"cpu\")),\n        ]\n    )\n    cifar10 = CIFAR10(root=save_path, train=train, download=True, transform=transform)\n    dataloader = torch.utils.data.DataLoader(\n        cifar10, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n    )\n    dataloader_subset = Subset(dataloader.dataset, range(n))\n    dataloader = DataLoader(\n        dataloader_subset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n    )\n    model = inception_v3(pretrained=True)\n    model.fc = torch.nn.Identity()  # replace the classifier with identity to get features\n    model.eval()\n    model = model.to(device if torch.cuda.is_available() else \"cpu\")\n    net = FIDEmbeddingNet(model)\n    embeddings = net.get_embeddings(dataloader)\n    return embeddings\n</code></pre>"},{"location":"api/#labproject.data.register_dataset","title":"<code>register_dataset(name)</code>","text":"<p>This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>Dataset generator function</p> required <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>Dataset generator function wrapper</p> Example <p>@register_dataset(\"random\") def random_dataset(n=1000, d=10):     return torch.randn(n, d)</p> Source code in <code>labproject/data.py</code> <pre><code>def register_dataset(name: str) -&gt; callable:\n    r\"\"\"This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.\n\n    Args:\n        func (callable): Dataset generator function\n\n    Returns:\n        callable: Dataset generator function wrapper\n\n    Example:\n        &gt;&gt;&gt; @register_dataset(\"random\")\n        &gt;&gt;&gt; def random_dataset(n=1000, d=10):\n        &gt;&gt;&gt;     return torch.randn(n, d)\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(n: int, d: Optional[int] = None, **kwargs):\n\n            assert n &gt; 0, \"n must be a positive integer\"\n            assert d &gt; 0, \"d must be a positive integer\"\n\n            # Call the original function\n            dataset = func(n, d, **kwargs)\n\n            # Convert the dataset to a PyTorch tensor\n            dataset = torch.Tensor(dataset) if not isinstance(dataset, torch.Tensor) else dataset\n\n            assert dataset.shape == (n, d), f\"Dataset shape must be {(n, d)}\"\n\n            return dataset\n\n        DATASETS[name] = wrapper\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/#labproject.data.register_distribution","title":"<code>register_distribution(name)</code>","text":"<p>This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>Dataset generator function</p> required <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>Dataset generator function wrapper</p> Example <p>@register_dataset(\"random\") def random_dataset(n=1000, d=10):     return torch.randn(n, d)</p> Source code in <code>labproject/data.py</code> <pre><code>def register_distribution(name: str) -&gt; callable:\n    r\"\"\"This decorator wrapps a function that should return a dataset and ensures that the dataset is a PyTorch tensor, with the correct shape.\n\n    Args:\n        func (callable): Dataset generator function\n\n    Returns:\n        callable: Dataset generator function wrapper\n\n    Example:\n        &gt;&gt;&gt; @register_dataset(\"random\")\n        &gt;&gt;&gt; def random_dataset(n=1000, d=10):\n        &gt;&gt;&gt;     return torch.randn(n, d)\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Call the original function\n            distribution = func(*args, **kwargs)\n            return distribution\n\n        DISTRIBUTIONS[name] = wrapper\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/#labproject.data.upload_file","title":"<code>upload_file(local_path, remote_path)</code>","text":"<p>Uploads a file to the Hetzner Storage Box.</p> <p>Parameters:</p> Name Type Description Default <code>local_path</code> <code>str</code> <p>The path to the local file to be uploaded.</p> required <code>remote_path</code> <code>str</code> <p>The path where the file should be uploaded on the remote server.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the upload is successful, False otherwise.</p> Example <p>if upload_file('path/to/your/local/file.txt', 'path/to/remote/file.txt'):     print(\"Upload successful\") else:     print(\"Upload failed\")</p> Source code in <code>labproject/data.py</code> <pre><code>def upload_file(local_path: str, remote_path: str):\n    r\"\"\"\n    Uploads a file to the Hetzner Storage Box.\n\n    Args:\n        local_path (str): The path to the local file to be uploaded.\n        remote_path (str): The path where the file should be uploaded on the remote server.\n\n    Returns:\n        bool: True if the upload is successful, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if upload_file('path/to/your/local/file.txt', 'path/to/remote/file.txt'):\n        &gt;&gt;&gt;     print(\"Upload successful\")\n        &gt;&gt;&gt; else:\n        &gt;&gt;&gt;     print(\"Upload failed\")\n    \"\"\"\n    url = f\"{STORAGEBOX_URL}/remote.php/dav/files/{HETZNER_STORAGEBOX_USERNAME}/{remote_path}\"\n    auth = HTTPBasicAuth(HETZNER_STORAGEBOX_USERNAME, HETZNER_STORAGEBOX_PASSWORD)\n    with open(local_path, \"rb\") as f:\n        data = f.read()\n    response = requests.put(url, data=data, auth=auth)\n    return response.status_code == 201\n</code></pre>"},{"location":"api/#embeddings","title":"Embeddings","text":"<p>This contains embedding nets, and auxilliary functions for extracting (N,D) embeddings from respective data and models.</p>"},{"location":"api/#experiments","title":"Experiments","text":""},{"location":"api/#labproject.experiments.ScaleDim","title":"<code>ScaleDim</code>","text":"<p>             Bases: <code>Experiment</code></p> Source code in <code>labproject/experiments.py</code> <pre><code>class ScaleDim(Experiment):\n\n    def __init__(self, metric_name, metric_fn, min_dim=1, max_dim=1000, step=100):\n        self.metric_name = metric_name\n        self.metric_fn = metric_fn\n        self.dimensionality = list(range(min_dim, max_dim, step))\n        super().__init__()\n\n    def run_experiment(self, dataset1, dataset2):\n        distances = []\n        for d in self.dimensionality:\n            distances.append(self.metric_fn(dataset1[:, :d], dataset2[:, :d]))\n        return self.dimensionality, distances\n\n    def plot_experiment(self, dimensionality, distances, dataset_name):\n        plot_scaling_metric_dimensionality(\n            dimensionality, distances, self.metric_name, dataset_name\n        )\n\n    def log_results(self, results, log_path):\n        \"\"\"\n        Save the results to a file.\n        \"\"\"\n        with open(log_path, \"wb\") as f:\n            pickle.dump(results, f)\n</code></pre>"},{"location":"api/#labproject.experiments.ScaleDim.log_results","title":"<code>log_results(results, log_path)</code>","text":"<p>Save the results to a file.</p> Source code in <code>labproject/experiments.py</code> <pre><code>def log_results(self, results, log_path):\n    \"\"\"\n    Save the results to a file.\n    \"\"\"\n    with open(log_path, \"wb\") as f:\n        pickle.dump(results, f)\n</code></pre>"},{"location":"api/#plotting","title":"Plotting","text":""},{"location":"api/#utils","title":"Utils","text":""},{"location":"api/#labproject.utils.get_cfg","title":"<code>get_cfg()</code>","text":"<p>This function returns the configuration file for the current experiment run.</p> <p>The configuration file is expected to be located at ../configs/conf_{name}.yaml, where name will match the name of the run_{name}.py file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration file is not found</p> <p>Returns:</p> Name Type Description <code>OmegaConf</code> <code>OmegaConf</code> <p>Dictionary with the configuration parameters</p> Source code in <code>labproject/utils.py</code> <pre><code>def get_cfg() -&gt; OmegaConf:\n    \"\"\"This function returns the configuration file for the current experiment run.\n\n    The configuration file is expected to be located at ../configs/conf_{name}.yaml, where name will match the name of the run_{name}.py file.\n\n    Raises:\n        FileNotFoundError: If the configuration file is not found\n\n    Returns:\n        OmegaConf: Dictionary with the configuration parameters\n    \"\"\"\n    caller_frame = inspect.currentframe().f_back\n    filename = caller_frame.f_code.co_filename\n    name = filename.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]\n    try:\n        config = OmegaConf.load(CONF_PATH + f\"/conf_{name}.yaml\")\n        config.running_user = name\n    except FileNotFoundError:\n        msg = f\"Config file not found for {name}. Please create a config file at ../configs/conf_{name}.yaml\"\n        raise FileNotFoundError(msg)\n    return config\n</code></pre>"},{"location":"api/#labproject.utils.get_log_path","title":"<code>get_log_path(cfg)</code>","text":"<p>Get the log path for the current experiment run. This log path is then used to save the numerical results of the experiment. Import this function in the run_{name}.py file and call it to get the log path.</p> Source code in <code>labproject/utils.py</code> <pre><code>def get_log_path(cfg):\n    \"\"\"\n    Get the log path for the current experiment run.\n    This log path is then used to save the numerical results of the experiment.\n    Import this function in the run_{name}.py file and call it to get the log path.\n    \"\"\"\n\n    # get datetime string\n    now = datetime.datetime.now()\n    if \"exp_log_name\" not in cfg:\n        exp_log_name = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n    else:\n        exp_log_name = cfg.exp_log_name\n        # add datetime to the name\n        exp_log_name = exp_log_name + \"_\" + now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n    log_path = os.path.join(f\"results/{cfg.running_user}/{exp_log_name}.pkl\")\n    return log_path\n</code></pre>"},{"location":"api/#labproject.utils.set_seed","title":"<code>set_seed(seed)</code>","text":"<p>Set seed for reproducibility</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Integer seed</p> required Source code in <code>labproject/utils.py</code> <pre><code>def set_seed(seed: int) -&gt; None:\n    \"\"\"Set seed for reproducibility\n\n    Args:\n        seed (int): Integer seed\n    \"\"\"\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    return seed\n</code></pre>"},{"location":"notebooks/example/","title":"Example notebook","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nnp.random.seed(0)\nimport matplotlib.pyplot as plt\n</pre> import numpy as np np.random.seed(0) import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>data = np.random.rand(100,2)\ndata.shape\n</pre> data = np.random.rand(100,2) data.shape Out[2]: <pre>(100, 2)</pre> In\u00a0[3]: Copied! <pre>plt.scatter(data[:,0], data[:,1])\n</pre> plt.scatter(data[:,0], data[:,1]) Out[3]: <pre>&lt;matplotlib.collections.PathCollection at 0x11bf91cd0&gt;</pre>"},{"location":"notebooks/example/#example-notebook","title":"Example notebook\u00b6","text":""},{"location":"notebooks/example/#create-data","title":"Create Data\u00b6","text":""},{"location":"notebooks/example/#visualize-data","title":"Visualize data\u00b6","text":""},{"location":"notebooks/fid/","title":"FID notebook","text":"In\u00a0[3]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[4]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import torch import torch.nn as nn import torch.nn.functional as F  import numpy as np import matplotlib.pyplot as plt  In\u00a0[5]: Copied! <pre>!pip install torchvision\n</pre> !pip install torchvision <pre>Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\nCollecting torchvision\n  Downloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: numpy in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (1.26.3)\nRequirement already satisfied: requests in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch==2.2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (2.2.0)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torchvision) (10.2.0)\nRequirement already satisfied: filelock in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions&gt;=4.8.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (4.9.0)\nRequirement already satisfied: sympy in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (1.12)\nRequirement already satisfied: networkx in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (3.1.3)\nRequirement already satisfied: fsspec in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2023.12.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from torch==2.2.0-&gt;torchvision) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch==2.2.0-&gt;torchvision) (12.3.101)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (2.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from requests-&gt;torchvision) (2023.11.17)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from jinja2-&gt;torch==2.2.0-&gt;torchvision) (2.1.4)\nRequirement already satisfied: mpmath&gt;=0.19 in /mnt/miniconda3/envs/labproject/lib/python3.9/site-packages (from sympy-&gt;torch==2.2.0-&gt;torchvision) (1.3.0)\nDownloading torchvision-0.17.0-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.9/6.9 MB 69.7 MB/s eta 0:00:00a 0:00:01\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.17.0\n</pre> In\u00a0[8]: Copied! <pre>import torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\n\ntransform = transforms.Compose([\n        transforms.Resize((299, 299)),\n        transforms.ToTensor(),\n        # normalize specific to inception model\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n# load CIFAR10 dataset\ncifar10_train = CIFAR10(root='/mnt_mount/labproject_data', train=True, download=True, transform=transform)\ncifar10_test = CIFAR10(root='/mnt_mount/labproject_data', train=False, download=True, transform=transform)\n</pre> import torchvision.transforms as transforms from torchvision.datasets import CIFAR10  transform = transforms.Compose([         transforms.Resize((299, 299)),         transforms.ToTensor(),         # normalize specific to inception model         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),     ])  # load CIFAR10 dataset cifar10_train = CIFAR10(root='/mnt_mount/labproject_data', train=True, download=True, transform=transform) cifar10_test = CIFAR10(root='/mnt_mount/labproject_data', train=False, download=True, transform=transform)  <pre>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt_mount/labproject_data/cifar-10-python.tar.gz\n</pre> <pre>100.0%\n</pre> <pre>Extracting /mnt_mount/labproject_data/cifar-10-python.tar.gz to /mnt_mount/labproject_data\nFiles already downloaded and verified\n</pre> In\u00a0[10]: Copied! <pre>dataloader_1 = torch.utils.data.DataLoader(cifar10_train, batch_size=100, shuffle=False, num_workers=1)\ndataloader_2 = torch.utils.data.DataLoader(cifar10_test, batch_size=100, shuffle=False, num_workers=1)\n</pre> dataloader_1 = torch.utils.data.DataLoader(cifar10_train, batch_size=100, shuffle=False, num_workers=1) dataloader_2 = torch.utils.data.DataLoader(cifar10_test, batch_size=100, shuffle=False, num_workers=1) In\u00a0[11]: Copied! <pre>from torchvision.models import inception_v3\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\n\n# get embedding net\ndef get_embedding_net():\n    model = inception_v3(pretrained=True)\n    model.fc = torch.nn.Identity()  # replace the classifier with identity to get features\n    model.eval()\n    return model.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n# extract features\ndef extract_features(dataloader, model):\n    features = []\n    with torch.no_grad():\n        for data, _ in dataloader:\n            data = data.to('cuda' if torch.cuda.is_available() else 'cpu')\n            features.append(model(data))\n    return torch.cat(features).cpu().numpy()\n\n\nembedding_net = get_embedding_net()\n\nfeatures1 = extract_features(dataloader_1, embedding_net)\nfeatures2 = extract_features(dataloader_2, embedding_net)\n</pre> from torchvision.models import inception_v3 from torchvision.datasets import ImageFolder from torch.utils.data import DataLoader import numpy as np   # get embedding net def get_embedding_net():     model = inception_v3(pretrained=True)     model.fc = torch.nn.Identity()  # replace the classifier with identity to get features     model.eval()     return model.to('cuda' if torch.cuda.is_available() else 'cpu')  # extract features def extract_features(dataloader, model):     features = []     with torch.no_grad():         for data, _ in dataloader:             data = data.to('cuda' if torch.cuda.is_available() else 'cpu')             features.append(model(data))     return torch.cat(features).cpu().numpy()   embedding_net = get_embedding_net()  features1 = extract_features(dataloader_1, embedding_net) features2 = extract_features(dataloader_2, embedding_net)  <pre>/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/mnt/miniconda3/envs/labproject/lib/python3.9/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\n</pre> In\u00a0[12]: Copied! <pre>features1.shape, features2.shape\n</pre> features1.shape, features2.shape Out[12]: <pre>((50000, 2048), (10000, 2048))</pre> In\u00a0[16]: Copied! <pre>from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance\n\nswd = sliced_wasserstein_distance(torch.from_numpy(features1)[:10000], torch.from_numpy(features2), num_projections=1000)\n</pre> from labproject.metrics.sliced_wasserstein import sliced_wasserstein_distance  swd = sliced_wasserstein_distance(torch.from_numpy(features1)[:10000], torch.from_numpy(features2), num_projections=1000) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}